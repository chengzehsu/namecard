name: "Enhanced Testing Strategy - Test Engineer Implementation"

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # æ¯æ—¥ UTC 02:00 åŸ·è¡ŒçœŸå¯¦ API æ¸¬è©¦
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'é¸æ“‡æ¸¬è©¦é¡å‹'
        required: true
        default: 'all'
        type: choice
        options:
        - 'all'
        - 'unit'
        - 'integration'
        - 'performance'
        - 'api'
        - 'security'

jobs:
  # 1. å¿«é€Ÿå–®å…ƒæ¸¬è©¦ (æ¯æ¬¡ Push åŸ·è¡Œ)
  unit-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v4
    
    - name: è¨­ç½® Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: å®‰è£ä¾è³´
      run: |
        python -m pip install --upgrade pip
        pip install -r deployment/environments/production/requirements.txt
        pip install pytest pytest-cov pytest-xdist pytest-benchmark
    
    - name: åŸ·è¡Œå–®å…ƒæ¸¬è©¦
      env:
        LINE_CHANNEL_ACCESS_TOKEN: 'test_token'
        LINE_CHANNEL_SECRET: 'test_secret'
        GOOGLE_API_KEY: 'test_key'
        NOTION_API_KEY: 'test_notion_key'
        NOTION_DATABASE_ID: 'test_db_id'
      run: |
        echo "ğŸ§ª åŸ·è¡Œå–®å…ƒæ¸¬è©¦å¥—ä»¶..."
        pytest tests/unit/ -v --cov=. --cov-report=term-missing --cov-report=xml \
          --maxfail=5 --tb=short -x
        
        echo "ğŸ“Š ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š..."
        pytest --cov=. --cov-report=html:htmlcov tests/unit/
    
    - name: ä¸Šå‚³è¦†è“‹ç‡å ±å‘Š
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-${{ matrix.python-version }}

  # 2. æ•´åˆæ¸¬è©¦ (Push åˆ° main åˆ†æ”¯åŸ·è¡Œ)
  integration-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: è¨­ç½® Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: å®‰è£ä¾è³´
      run: |
        python -m pip install --upgrade pip
        pip install -r deployment/environments/production/requirements.txt
        pip install pytest pytest-asyncio
    
    - name: åŸ·è¡Œæ•´åˆæ¸¬è©¦
      env:
        LINE_CHANNEL_ACCESS_TOKEN: 'test_token'
        LINE_CHANNEL_SECRET: 'test_secret'
        GOOGLE_API_KEY: 'test_key'
        NOTION_API_KEY: 'test_notion_key'
        NOTION_DATABASE_ID: 'test_db_id'
      run: |
        echo "ğŸ”„ åŸ·è¡Œæ•´åˆæ¸¬è©¦..."
        pytest tests/integration/ -v --tb=short --maxfail=3
        
        echo "ğŸ“ åŸ·è¡Œç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æ¸¬è©¦..."
        pytest tests/integration/test_end_to_end_workflow.py -v -s

  # 3. æ•ˆèƒ½æ¸¬è©¦ (æ‰‹å‹•è§¸ç™¼æˆ–å®šæœŸåŸ·è¡Œ)
  performance-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: è¨­ç½® Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: å®‰è£ä¾è³´
      run: |
        python -m pip install --upgrade pip
        pip install -r deployment/environments/production/requirements.txt
        pip install pytest pytest-benchmark psutil
    
    - name: åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦
      run: |
        echo "âš¡ åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦å¥—ä»¶..."
        pytest tests/performance/ -v -s --tb=short \
          --benchmark-only --benchmark-sort=mean
        
        echo "ğŸ“Š ç”Ÿæˆæ•ˆèƒ½å ±å‘Š..."
        pytest tests/performance/test_load_testing.py::test_comparison_batch_managers \
          --benchmark-json=benchmark_results.json
    
    - name: ä¸Šå‚³æ•ˆèƒ½å ±å‘Š
      uses: actions/upload-artifact@v3
      with:
        name: performance-report
        path: benchmark_results.json

  # 4. çœŸå¯¦ API æ¸¬è©¦ (åƒ…åœ¨æœ‰ API é‡‘é‘°æ™‚åŸ·è¡Œ)
  real-api-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.test_type == 'api')
    
    steps:
    - uses: actions/checkout@v4
    
    - name: è¨­ç½® Python 3.11  
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: å®‰è£ä¾è³´
      run: |
        python -m pip install --upgrade pip
        pip install -r deployment/environments/production/requirements.txt
        pip install pytest requests
    
    - name: åŸ·è¡ŒçœŸå¯¦ API æ¸¬è©¦
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        NOTION_API_KEY: ${{ secrets.NOTION_API_KEY }}
        NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}
      run: |
        echo "ğŸŒ åŸ·è¡ŒçœŸå¯¦ API æ•´åˆæ¸¬è©¦..."
        
        # å¥åº·æª¢æŸ¥
        pytest tests/api_integration/test_real_apis.py::TestAPIHealthChecks \
          -v -s --tb=short -m "health_check"
        
        # çœŸå¯¦ API æ¸¬è©¦ (å¦‚æœæœ‰ API é‡‘é‘°)
        if [ -n "$GOOGLE_API_KEY" ] && [ -n "$NOTION_API_KEY" ]; then
          echo "ğŸ”‘ API é‡‘é‘°å¯ç”¨ï¼ŒåŸ·è¡Œå®Œæ•´ API æ¸¬è©¦..."
          pytest tests/api_integration/test_real_apis.py::TestRealAPIIntegration \
            -v -s --tb=short -m "api and not slow" --maxfail=2
        else
          echo "âš ï¸ API é‡‘é‘°ä¸å¯ç”¨ï¼Œè·³éçœŸå¯¦ API æ¸¬è©¦"
        fi

  # 5. å®‰å…¨æ¸¬è©¦
  security-tests:
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: è¨­ç½® Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: å®‰è£å®‰å…¨å·¥å…·
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety semgrep
    
    - name: åŸ·è¡Œå®‰å…¨æƒæ
      run: |
        echo "ğŸ”’ åŸ·è¡Œå®‰å…¨æ¼æ´æƒæ..."
        
        # Bandit å®‰å…¨æƒæ
        echo "ğŸ” Bandit éœæ…‹åˆ†æ..."
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . -f txt
        
        # Safety ä¾è³´å®‰å…¨æª¢æŸ¥
        echo "ğŸ“¦ Safety ä¾è³´æª¢æŸ¥..."
        safety check --json --output safety-report.json || true
        safety check
        
        # Semgrep ä»£ç¢¼å®‰å…¨æƒæ
        echo "ğŸ” Semgrep å®‰å…¨è¦å‰‡æª¢æŸ¥..."
        semgrep --config=auto . --json --output=semgrep-report.json || true
    
    - name: ä¸Šå‚³å®‰å…¨å ±å‘Š
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  # 6. æ¸¬è©¦å ±å‘ŠåŒ¯ç¸½
  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, security-tests]
    if: always()
    
    steps:
    - name: åŒ¯ç¸½æ¸¬è©¦çµæœ
      run: |
        echo "ğŸ“Š æ¸¬è©¦åŸ·è¡Œæ‘˜è¦:"
        echo "===================="
        
        echo "âœ… å–®å…ƒæ¸¬è©¦: ${{ needs.unit-tests.result }}"
        echo "âœ… æ•´åˆæ¸¬è©¦: ${{ needs.integration-tests.result }}"  
        echo "âœ… å®‰å…¨æ¸¬è©¦: ${{ needs.security-tests.result }}"
        
        # è¨ˆç®—æ•´é«”ç‹€æ…‹
        if [[ "${{ needs.unit-tests.result }}" == "success" ]] && \
           [[ "${{ needs.security-tests.result }}" == "success" ]]; then
          echo "ğŸ‰ æ ¸å¿ƒæ¸¬è©¦é€šéï¼"
          echo "test_status=success" >> $GITHUB_ENV
        else
          echo "âŒ å­˜åœ¨æ¸¬è©¦å¤±æ•—"
          echo "test_status=failure" >> $GITHUB_ENV
        fi
    
    - name: é€šçŸ¥æ¸¬è©¦çµæœ
      if: github.ref == 'refs/heads/main'
      run: |
        echo "ğŸ“¢ æ¸¬è©¦çµæœé€šçŸ¥:"
        echo "åˆ†æ”¯: ${{ github.ref }}"
        echo "æäº¤: ${{ github.sha }}"
        echo "ç‹€æ…‹: ${{ env.test_status }}"

  # 7. æ¸¬è©¦æŒ‡æ¨™è¿½è¹¤ (å¯é¸)
  test-metrics:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0  # ç²å–å®Œæ•´æ­·å²
    
    - name: åˆ†ææ¸¬è©¦è¶¨å‹¢
      run: |
        echo "ğŸ“ˆ åˆ†ææ¸¬è©¦æŒ‡æ¨™è¶¨å‹¢..."
        
        # çµ±è¨ˆæ¸¬è©¦æ–‡ä»¶æ•¸é‡
        unit_tests=$(find tests/unit -name "test_*.py" | wc -l)
        integration_tests=$(find tests/integration -name "test_*.py" | wc -l)
        total_tests=$((unit_tests + integration_tests))
        
        echo "æ¸¬è©¦æ–‡ä»¶çµ±è¨ˆ:"
        echo "- å–®å…ƒæ¸¬è©¦: $unit_tests å€‹æ–‡ä»¶"
        echo "- æ•´åˆæ¸¬è©¦: $integration_tests å€‹æ–‡ä»¶"
        echo "- ç¸½è¨ˆ: $total_tests å€‹æ¸¬è©¦æ–‡ä»¶"
        
        # è¨ˆç®—ä»£ç¢¼è¡Œæ•¸
        python_lines=$(find . -name "*.py" -not -path "./venv/*" -not -path "./.venv/*" | xargs wc -l | tail -1 | awk '{print $1}')
        test_lines=$(find tests/ -name "*.py" | xargs wc -l | tail -1 | awk '{print $1}')
        
        echo "ä»£ç¢¼çµ±è¨ˆ:"
        echo "- æ‡‰ç”¨ç¨‹å¼ä»£ç¢¼: $python_lines è¡Œ"
        echo "- æ¸¬è©¦ä»£ç¢¼: $test_lines è¡Œ"
        echo "- æ¸¬è©¦è¦†è“‹æ¯”: $(( test_lines * 100 / python_lines ))%"