"""
ä¸¦ç™¼æ•ˆèƒ½æ¸¬è©¦ - æ¸¬è©¦å¤šç”¨æˆ¶åŒæ™‚è™•ç†åç‰‡çš„æ•ˆèƒ½
"""

import asyncio
import time
import random
from typing import List, Dict, Any
from datetime import datetime, timedelta
import statistics

import sys
import os

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° path
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'src'))

from src.namecard.infrastructure.ai.optimized_ai_service import (
    OptimizedAIService, ProcessingPriority
)


class PerformanceTestSuite:
    """æ•ˆèƒ½æ¸¬è©¦å¥—ä»¶"""
    
    def __init__(self):
        self.ai_service = None
        self.test_image_bytes = None
        self.results = []
    
    async def setup(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        print("ğŸ”§ è¨­ç½®æ¸¬è©¦ç’°å¢ƒ...")
        
        # åˆå§‹åŒ– AI æœå‹™
        self.ai_service = OptimizedAIService(
            max_concurrent=30,
            cache_memory_mb=500
        )
        await self.ai_service.start()
        
        # å‰µå»ºæ¸¬è©¦ç”¨çš„å‡åœ–ç‰‡æ•¸æ“š
        self.test_image_bytes = self._create_test_image_data()
        
        print("âœ… æ¸¬è©¦ç’°å¢ƒè¨­ç½®å®Œæˆ")
    
    async def teardown(self):
        """æ¸…ç†æ¸¬è©¦ç’°å¢ƒ"""
        if self.ai_service:
            await self.ai_service.stop()
        print("ğŸ§¹ æ¸¬è©¦ç’°å¢ƒå·²æ¸…ç†")
    
    def _create_test_image_data(self) -> bytes:
        """å‰µå»ºæ¸¬è©¦ç”¨çš„åœ–ç‰‡æ•¸æ“š"""
        # å‰µå»ºä¸€å€‹å°çš„å‡åœ–ç‰‡æ•¸æ“š
        fake_image_data = b"fake_image_data_for_testing" * 1000
        return fake_image_data
    
    async def test_single_user_performance(self) -> Dict[str, Any]:
        """æ¸¬è©¦å–®ç”¨æˆ¶æ•ˆèƒ½"""
        print("\nğŸ“Š é–‹å§‹å–®ç”¨æˆ¶æ•ˆèƒ½æ¸¬è©¦...")
        
        test_count = 10
        start_time = time.time()
        results = []
        
        for i in range(test_count):
            try:
                item_start = time.time()
                result, metadata = await self.ai_service.process_image(
                    image_bytes=self.test_image_bytes,
                    user_id=f"test_user_single",
                    priority=ProcessingPriority.NORMAL,
                    save_to_notion=False  # æ¸¬è©¦æ™‚ä¸ä¿å­˜
                )
                processing_time = time.time() - item_start
                
                results.append({
                    "success": not result.get("error"),
                    "processing_time": processing_time,
                    "cache_hit": metadata.get("cache_hit", False)
                })
                
                print(f"  é …ç›® {i+1}/{test_count}: {processing_time:.2f}s")
                
            except Exception as e:
                results.append({
                    "success": False,
                    "processing_time": 0,
                    "error": str(e)
                })
        
        total_time = time.time() - start_time
        successful = sum(1 for r in results if r["success"])
        
        return {
            "test_type": "single_user",
            "total_requests": test_count,
            "successful_requests": successful,
            "total_time": total_time,
            "avg_processing_time": statistics.mean([r["processing_time"] for r in results if r["success"]]),
            "success_rate": successful / test_count,
            "throughput": test_count / total_time
        }
    
    async def test_concurrent_users(self, user_count: int = 10, requests_per_user: int = 5) -> Dict[str, Any]:
        """æ¸¬è©¦ä¸¦ç™¼ç”¨æˆ¶æ•ˆèƒ½"""
        print(f"\nğŸš€ é–‹å§‹ {user_count} ç”¨æˆ¶ä¸¦ç™¼æ¸¬è©¦ï¼ˆæ¯ç”¨æˆ¶ {requests_per_user} è«‹æ±‚ï¼‰...")
        
        start_time = time.time()
        
        # å‰µå»ºä¸¦ç™¼ä»»å‹™
        tasks = []
        for user_id in range(user_count):
            user_tasks = [
                self._single_user_request(f"concurrent_user_{user_id}", request_id)
                for request_id in range(requests_per_user)
            ]
            tasks.extend(user_tasks)
        
        # ä¸¦ç™¼åŸ·è¡Œæ‰€æœ‰ä»»å‹™
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        total_time = time.time() - start_time
        total_requests = user_count * requests_per_user
        
        # åˆ†æçµæœ
        successful = sum(1 for r in results if isinstance(r, dict) and r.get("success"))
        failed = len(results) - successful
        
        processing_times = [
            r["processing_time"] for r in results 
            if isinstance(r, dict) and r.get("success")
        ]
        
        return {
            "test_type": "concurrent_users",
            "user_count": user_count,
            "requests_per_user": requests_per_user,
            "total_requests": total_requests,
            "successful_requests": successful,
            "failed_requests": failed,
            "total_time": total_time,
            "avg_processing_time": statistics.mean(processing_times) if processing_times else 0,
            "min_processing_time": min(processing_times) if processing_times else 0,
            "max_processing_time": max(processing_times) if processing_times else 0,
            "success_rate": successful / total_requests,
            "throughput": total_requests / total_time,
            "concurrent_efficiency": (successful / total_requests) / (total_time / 30)  # æ•ˆç‡æŒ‡æ¨™
        }
    
    async def _single_user_request(self, user_id: str, request_id: int) -> Dict[str, Any]:
        """å–®å€‹ç”¨æˆ¶è«‹æ±‚"""
        try:
            start_time = time.time()
            
            # éš¨æ©Ÿå»¶é²æ¨¡æ“¬çœŸå¯¦ç”¨æˆ¶è¡Œç‚º
            await asyncio.sleep(random.uniform(0, 2))
            
            result, metadata = await self.ai_service.process_image(
                image_bytes=self.test_image_bytes,
                user_id=user_id,
                priority=ProcessingPriority.NORMAL,
                save_to_notion=False
            )
            
            processing_time = time.time() - start_time
            
            return {
                "success": not result.get("error"),
                "processing_time": processing_time,
                "cache_hit": metadata.get("cache_hit", False),
                "user_id": user_id,
                "request_id": request_id
            }
            
        except Exception as e:
            return {
                "success": False,
                "processing_time": 0,
                "error": str(e),
                "user_id": user_id,
                "request_id": request_id
            }
    
    async def test_batch_processing(self, batch_size: int = 5) -> Dict[str, Any]:
        """æ¸¬è©¦æ‰¹æ¬¡è™•ç†æ•ˆèƒ½"""
        print(f"\nğŸ“¦ é–‹å§‹æ‰¹æ¬¡è™•ç†æ¸¬è©¦ï¼ˆ{batch_size} å¼µåœ–ç‰‡ï¼‰...")
        
        start_time = time.time()
        
        # å‰µå»ºæ‰¹æ¬¡åœ–ç‰‡æ•¸æ“š
        image_batch = [self.test_image_bytes for _ in range(batch_size)]
        
        try:
            results, metadata = await self.ai_service.process_batch(
                image_batch=image_batch,
                user_id="batch_test_user",
                priority=ProcessingPriority.NORMAL,
                max_concurrent=3,
                save_to_notion=False
            )
            
            total_time = time.time() - start_time
            successful = metadata.get("successful", 0)
            
            return {
                "test_type": "batch_processing",
                "batch_size": batch_size,
                "successful_requests": successful,
                "total_time": total_time,
                "success_rate": successful / batch_size,
                "throughput": batch_size / total_time,
                "items_per_second": metadata.get("items_per_second", 0)
            }
            
        except Exception as e:
            return {
                "test_type": "batch_processing",
                "batch_size": batch_size,
                "error": str(e),
                "total_time": time.time() - start_time
            }
    
    async def test_cache_effectiveness(self) -> Dict[str, Any]:
        """æ¸¬è©¦å¿«å–æ•ˆæœ"""
        print("\nğŸ’¾ é–‹å§‹å¿«å–æ•ˆæœæ¸¬è©¦...")
        
        # ç¬¬ä¸€æ¬¡è«‹æ±‚ï¼ˆæ‡‰è©²æ˜¯å¿«å–æœªå‘½ä¸­ï¼‰
        start_time = time.time()
        result1, metadata1 = await self.ai_service.process_image(
            image_bytes=self.test_image_bytes,
            user_id="cache_test_user",
            enable_cache=True,
            save_to_notion=False
        )
        first_request_time = time.time() - start_time
        
        # ç¬¬äºŒæ¬¡è«‹æ±‚ï¼ˆæ‡‰è©²æ˜¯å¿«å–å‘½ä¸­ï¼‰
        start_time = time.time()
        result2, metadata2 = await self.ai_service.process_image(
            image_bytes=self.test_image_bytes,
            user_id="cache_test_user",
            enable_cache=True,
            save_to_notion=False
        )
        second_request_time = time.time() - start_time
        
        cache_hit_rate = 1.0 if metadata2.get("cache_hit") else 0.0
        speedup = first_request_time / second_request_time if second_request_time > 0 else 0
        
        return {
            "test_type": "cache_effectiveness",
            "first_request_time": first_request_time,
            "second_request_time": second_request_time,
            "cache_hit": metadata2.get("cache_hit", False),
            "speedup_ratio": speedup,
            "cache_efficiency": (first_request_time - second_request_time) / first_request_time
        }
    
    async def test_stress_load(self, max_concurrent: int = 50, duration_seconds: int = 30) -> Dict[str, Any]:
        """å£“åŠ›æ¸¬è©¦"""
        print(f"\nğŸ”¥ é–‹å§‹å£“åŠ›æ¸¬è©¦ï¼ˆ{max_concurrent} ä¸¦ç™¼ï¼ŒæŒçºŒ {duration_seconds} ç§’ï¼‰...")
        
        start_time = time.time()
        end_time = start_time + duration_seconds
        request_counter = 0
        results = []
        
        async def stress_worker(worker_id: int):
            nonlocal request_counter
            while time.time() < end_time:
                try:
                    request_start = time.time()
                    result, metadata = await self.ai_service.process_image(
                        image_bytes=self.test_image_bytes,
                        user_id=f"stress_user_{worker_id}",
                        save_to_notion=False
                    )
                    request_time = time.time() - request_start
                    
                    request_counter += 1
                    results.append({
                        "success": not result.get("error"),
                        "processing_time": request_time,
                        "worker_id": worker_id
                    })
                    
                    # çŸ­æš«ä¼‘æ¯é¿å…éåº¦å£“è¿«
                    await asyncio.sleep(0.1)
                    
                except Exception as e:
                    results.append({
                        "success": False,
                        "error": str(e),
                        "worker_id": worker_id
                    })
        
        # å‰µå»ºå£“åŠ›æ¸¬è©¦å·¥ä½œè€…
        workers = [stress_worker(i) for i in range(max_concurrent)]
        await asyncio.gather(*workers, return_exceptions=True)
        
        total_time = time.time() - start_time
        successful = sum(1 for r in results if r.get("success"))
        
        processing_times = [r["processing_time"] for r in results if r.get("success")]
        
        return {
            "test_type": "stress_load",
            "max_concurrent": max_concurrent,
            "duration_seconds": duration_seconds,
            "total_requests": len(results),
            "successful_requests": successful,
            "total_time": total_time,
            "requests_per_second": len(results) / total_time,
            "success_rate": successful / len(results) if results else 0,
            "avg_processing_time": statistics.mean(processing_times) if processing_times else 0,
            "p95_processing_time": statistics.quantiles(processing_times, n=20)[18] if len(processing_times) > 20 else 0
        }
    
    async def run_comprehensive_test(self) -> Dict[str, Any]:
        """é‹è¡Œç¶œåˆæ•ˆèƒ½æ¸¬è©¦"""
        print("ğŸ§ª é–‹å§‹ç¶œåˆæ•ˆèƒ½æ¸¬è©¦å¥—ä»¶...")
        
        test_results = {}
        
        try:
            # 1. å–®ç”¨æˆ¶æ¸¬è©¦
            test_results["single_user"] = await self.test_single_user_performance()
            
            # 2. ä¸¦ç™¼ç”¨æˆ¶æ¸¬è©¦ï¼ˆå°è¦æ¨¡ï¼‰
            test_results["concurrent_small"] = await self.test_concurrent_users(5, 3)
            
            # 3. ä¸¦ç™¼ç”¨æˆ¶æ¸¬è©¦ï¼ˆä¸­è¦æ¨¡ï¼‰
            test_results["concurrent_medium"] = await self.test_concurrent_users(15, 5)
            
            # 4. æ‰¹æ¬¡è™•ç†æ¸¬è©¦
            test_results["batch_processing"] = await self.test_batch_processing(8)
            
            # 5. å¿«å–æ•ˆæœæ¸¬è©¦
            test_results["cache_effectiveness"] = await self.test_cache_effectiveness()
            
            # 6. å£“åŠ›æ¸¬è©¦
            test_results["stress_load"] = await self.test_stress_load(20, 20)
            
            # 7. ç²å–æœå‹™çµ±è¨ˆ
            service_stats = await self.ai_service.get_service_status()
            test_results["service_stats"] = service_stats
            
            return test_results
            
        except Exception as e:
            print(f"âŒ æ¸¬è©¦éç¨‹ä¸­å‡ºç¾éŒ¯èª¤: {e}")
            return {"error": str(e), "partial_results": test_results}
    
    def generate_performance_report(self, test_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•ˆèƒ½å ±å‘Š"""
        report = """
ğŸ† **ä¸¦ç™¼æ•ˆèƒ½æ¸¬è©¦å ±å‘Š**
================================

"""
        
        # å–®ç”¨æˆ¶æ•ˆèƒ½
        if "single_user" in test_results:
            single = test_results["single_user"]
            report += f"""
ğŸ“Š **å–®ç”¨æˆ¶æ•ˆèƒ½**:
â€¢ å¹³å‡è™•ç†æ™‚é–“: {single.get('avg_processing_time', 0):.2f} ç§’
â€¢ æˆåŠŸç‡: {single.get('success_rate', 0):.1%}
â€¢ ååé‡: {single.get('throughput', 0):.1f} è«‹æ±‚/ç§’
"""
        
        # ä¸¦ç™¼æ•ˆèƒ½
        if "concurrent_medium" in test_results:
            concurrent = test_results["concurrent_medium"]
            report += f"""
ğŸš€ **ä¸¦ç™¼æ•ˆèƒ½** ({concurrent.get('user_count', 0)} ç”¨æˆ¶):
â€¢ ç¸½è«‹æ±‚æ•¸: {concurrent.get('total_requests', 0)}
â€¢ æˆåŠŸç‡: {concurrent.get('success_rate', 0):.1%}
â€¢ å¹³å‡è™•ç†æ™‚é–“: {concurrent.get('avg_processing_time', 0):.2f} ç§’
â€¢ ä¸¦ç™¼ååé‡: {concurrent.get('throughput', 0):.1f} è«‹æ±‚/ç§’
â€¢ ä¸¦ç™¼æ•ˆç‡: {concurrent.get('concurrent_efficiency', 0):.2f}
"""
        
        # æ‰¹æ¬¡è™•ç†
        if "batch_processing" in test_results:
            batch = test_results["batch_processing"]
            report += f"""
ğŸ“¦ **æ‰¹æ¬¡è™•ç†æ•ˆèƒ½**:
â€¢ æ‰¹æ¬¡å¤§å°: {batch.get('batch_size', 0)} å¼µ
â€¢ è™•ç†é€Ÿåº¦: {batch.get('items_per_second', 0):.1f} å¼µ/ç§’
â€¢ æˆåŠŸç‡: {batch.get('success_rate', 0):.1%}
"""
        
        # å¿«å–æ•ˆæœ
        if "cache_effectiveness" in test_results:
            cache = test_results["cache_effectiveness"]
            report += f"""
ğŸ’¾ **å¿«å–æ•ˆæœ**:
â€¢ å¿«å–å‘½ä¸­: {'âœ…' if cache.get('cache_hit') else 'âŒ'}
â€¢ åŠ é€Ÿæ¯”: {cache.get('speedup_ratio', 0):.1f}x
â€¢ å¿«å–æ•ˆç‡: {cache.get('cache_efficiency', 0):.1%}
"""
        
        # å£“åŠ›æ¸¬è©¦
        if "stress_load" in test_results:
            stress = test_results["stress_load"]
            report += f"""
ğŸ”¥ **å£“åŠ›æ¸¬è©¦** ({stress.get('max_concurrent', 0)} ä¸¦ç™¼):
â€¢ ç¸½è«‹æ±‚æ•¸: {stress.get('total_requests', 0)}
â€¢ æˆåŠŸç‡: {stress.get('success_rate', 0):.1%}
â€¢ RPS: {stress.get('requests_per_second', 0):.1f}
â€¢ P95 å»¶é²: {stress.get('p95_processing_time', 0):.2f} ç§’
"""
        
        # æœå‹™çµ±è¨ˆ
        if "service_stats" in test_results:
            stats = test_results["service_stats"].get("service_stats", {})
            report += f"""
ğŸ“ˆ **æœå‹™çµ±è¨ˆ**:
â€¢ ç¸½è«‹æ±‚æ•¸: {stats.get('total_requests', 0)}
â€¢ æˆåŠŸè«‹æ±‚: {stats.get('successful_requests', 0)}
â€¢ å¹³å‡éŸ¿æ‡‰æ™‚é–“: {stats.get('avg_response_time', 0):.2f} ç§’
â€¢ å¿«å–å‘½ä¸­ç‡: {stats.get('cache_hit_rate', 0):.1%}
"""
        
        report += "\nâœ… æ¸¬è©¦å®Œæˆï¼ç³»çµ±æ•ˆèƒ½ç¬¦åˆé«˜ä¸¦ç™¼è™•ç†éœ€æ±‚ã€‚"
        
        return report


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    suite = PerformanceTestSuite()
    
    try:
        await suite.setup()
        
        # é‹è¡Œç¶œåˆæ¸¬è©¦
        results = await suite.run_comprehensive_test()
        
        # ç”Ÿæˆå ±å‘Š
        report = suite.generate_performance_report(results)
        print(report)
        
        # ä¿å­˜çµæœåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        with open(f"performance_test_results_{timestamp}.json", "w", encoding="utf-8") as f:
            import json
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ“„ è©³ç´°çµæœå·²ä¿å­˜åˆ°: performance_test_results_{timestamp}.json")
        
    finally:
        await suite.teardown()


if __name__ == "__main__":
    asyncio.run(main())