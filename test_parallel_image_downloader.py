#!/usr/bin/env python3
"""
ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨å®Œæ•´æ¸¬è©¦å¥—ä»¶ - Performance Benchmarker Agent å¯¦ä½œ
æ¸¬è©¦ ParallelImageDownloader çš„ä¸‹è¼‰æ•ˆèƒ½ã€å¿«å–æ©Ÿåˆ¶å’ŒéŒ¯èª¤è™•ç†åŠŸèƒ½
"""

import asyncio
import hashlib
import os
import shutil
import tempfile
import time
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

# å°å…¥æ¸¬è©¦ç›®æ¨™
from src.namecard.infrastructure.messaging.parallel_image_downloader import (
    DownloadResult,
    ParallelImageDownloader,
    benchmark_download_speed,
    create_optimized_downloader,
)


class TestParallelImageDownloader:
    """ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨æ¸¬è©¦é¡"""

    @pytest.fixture
    def temp_cache_dir(self):
        """å‰µå»ºè‡¨æ™‚å¿«å–ç›®éŒ„"""
        temp_dir = tempfile.mkdtemp(prefix="test_image_cache_")
        yield Path(temp_dir)
        # æ¸…ç†
        shutil.rmtree(temp_dir, ignore_errors=True)

    @pytest.fixture
    async def downloader(self, temp_cache_dir):
        """å‰µå»ºæ¸¬è©¦ç”¨çš„ä¸‹è¼‰å™¨"""
        downloader = ParallelImageDownloader(
            max_connections=10,
            max_per_host=5,
            timeout_seconds=15,
            enable_cache=True,
            cache_size_mb=50,
        )
        # è¨­ç½®è‡¨æ™‚å¿«å–ç›®éŒ„
        downloader.cache_dir = temp_cache_dir

        yield downloader

        # æ¸…ç†
        await downloader.cleanup()

    @pytest.fixture
    def mock_telegram_files(self):
        """æ¨¡æ“¬çš„ Telegram File ç‰©ä»¶"""
        files = []

        for i in range(5):
            mock_file = MagicMock()
            mock_file.file_id = f"test_file_id_{i}"
            mock_file.file_size = 1024 * (50 + i * 10)  # 50-90KB

            # æ¨¡æ“¬ä¸‹è¼‰æ–¹æ³•
            async def download_as_bytearray():
                await asyncio.sleep(0.1)  # æ¨¡æ“¬ç¶²è·¯å»¶é²
                return b"fake_image_data_" + str(i).encode() * 1000

            mock_file.download_as_bytearray = download_as_bytearray
            files.append(mock_file)

        return files

    @pytest.fixture
    def sample_image_data(self):
        """æ¸¬è©¦ç”¨çš„åœ–ç‰‡æ•¸æ“š"""
        return {
            "small": b"small_image_data" * 100,  # ~1.8KB
            "medium": b"medium_image_data" * 1000,  # ~18KB
            "large": b"large_image_data" * 10000,  # ~180KB
            "huge": b"huge_image_data" * 100000,  # ~1.8MB
        }

    # ==========================================
    # 1. åŸºç¤åŠŸèƒ½æ¸¬è©¦
    # ==========================================

    def test_download_result_creation(self):
        """æ¸¬è©¦ä¸‹è¼‰çµæœç‰©ä»¶å‰µå»º"""
        result = DownloadResult(
            success=True,
            data=b"test_data",
            download_time=2.5,
            file_size=1024,
            source="download",
            optimizations=["cached", "compressed"],
        )

        assert result.success is True
        assert result.data == b"test_data"
        assert result.download_time == 2.5
        assert result.file_size == 1024
        assert result.source == "download"
        assert "cached" in result.optimizations

    async def test_downloader_initialization(self, downloader):
        """æ¸¬è©¦ä¸‹è¼‰å™¨åˆå§‹åŒ–"""
        assert downloader.max_connections == 10
        assert downloader.max_per_host == 5
        assert downloader.timeout_seconds == 15
        assert downloader.enable_cache is True
        assert downloader.session is None  # å»¶é²å‰µå»º

        # æª¢æŸ¥çµ±è¨ˆåˆå§‹åŒ–
        expected_stats = [
            "total_downloads",
            "cache_hits",
            "parallel_downloads",
            "avg_download_time",
            "total_bytes_downloaded",
            "error_count",
        ]
        for stat in expected_stats:
            assert stat in downloader.stats
            assert downloader.stats[stat] == 0

    async def test_session_creation_and_optimization(self, downloader):
        """æ¸¬è©¦ HTTP æœƒè©±å‰µå»ºå’Œå„ªåŒ–"""
        session = await downloader._get_session()

        assert session is not None
        assert downloader.session is session

        # æª¢æŸ¥é€£æ¥å™¨é…ç½®
        connector = session.connector
        assert connector.limit == 10
        assert connector.limit_per_host == 5

        # æª¢æŸ¥è¶…æ™‚é…ç½®
        timeout = session.timeout
        assert timeout.total == 15

    def test_cache_key_generation(self, downloader):
        """æ¸¬è©¦å¿«å–éµç”Ÿæˆ"""
        file_id = "test_file_123"
        cache_key = downloader._get_cache_key(file_id)

        # æª¢æŸ¥æ˜¯ MD5 hash
        assert len(cache_key) == 32
        assert cache_key == hashlib.md5(file_id.encode()).hexdigest()

        # ç›¸åŒè¼¸å…¥æ‡‰è©²ç”¢ç”Ÿç›¸åŒéµå€¼
        assert downloader._get_cache_key(file_id) == cache_key

    def test_cache_path_generation(self, downloader, temp_cache_dir):
        """æ¸¬è©¦å¿«å–è·¯å¾‘ç”Ÿæˆ"""
        cache_key = "test_cache_key"
        cache_path = downloader._get_cache_path(cache_key)

        assert cache_path.parent == temp_cache_dir
        assert cache_path.suffix == ".jpg"
        assert cache_key in str(cache_path)

    # ==========================================
    # 2. å¿«å–æ©Ÿåˆ¶æ¸¬è©¦
    # ==========================================

    async def test_cache_store_and_retrieve(self, downloader, sample_image_data):
        """æ¸¬è©¦å¿«å–å­˜å„²å’Œæª¢ç´¢"""
        file_id = "test_cache_file"
        image_data = sample_image_data["medium"]

        # å­˜å„²åˆ°å¿«å–
        await downloader._store_cache(file_id, image_data)

        # æª¢ç´¢å¿«å–
        cached_data = await downloader._check_cache(file_id)

        assert cached_data is not None
        assert cached_data == image_data
        assert downloader.stats["cache_hits"] == 1

    async def test_cache_miss(self, downloader):
        """æ¸¬è©¦å¿«å–æœªå‘½ä¸­"""
        non_existent_file = "non_existent_file_id"
        cached_data = await downloader._check_cache(non_existent_file)

        assert cached_data is None
        assert downloader.stats["cache_hits"] == 0

    async def test_cache_disabled(self, temp_cache_dir):
        """æ¸¬è©¦é—œé–‰å¿«å–åŠŸèƒ½"""
        downloader = ParallelImageDownloader(enable_cache=False, cache_size_mb=50)
        downloader.cache_dir = temp_cache_dir

        try:
            file_id = "test_no_cache"
            image_data = b"test_data" * 100

            # å˜—è©¦å­˜å„²åˆ°å¿«å–ï¼ˆæ‡‰è©²è¢«è·³éï¼‰
            await downloader._store_cache(file_id, image_data)

            # æª¢æŸ¥å¿«å–ï¼ˆæ‡‰è©²è¿”å› Noneï¼‰
            cached_data = await downloader._check_cache(file_id)
            assert cached_data is None

        finally:
            await downloader.cleanup()

    async def test_cache_corruption_handling(self, downloader, temp_cache_dir):
        """æ¸¬è©¦æå£å¿«å–æ–‡ä»¶è™•ç†"""
        file_id = "corrupt_cache_test"
        cache_key = downloader._get_cache_key(file_id)
        cache_path = downloader._get_cache_path(cache_key)

        # å‰µå»ºæå£çš„å¿«å–æ–‡ä»¶
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        with open(cache_path, "w") as f:
            f.write("corrupted_binary_data")

        # å˜—è©¦è®€å–æ‡‰è©²å¤±æ•—ä¸¦æ¸…ç†æ–‡ä»¶
        cached_data = await downloader._check_cache(file_id)

        assert cached_data is None
        assert not cache_path.exists()  # æå£æ–‡ä»¶æ‡‰è©²è¢«åˆªé™¤

    async def test_cache_size_limit(self, downloader, sample_image_data):
        """æ¸¬è©¦å¿«å–å¤§å°é™åˆ¶"""
        # è¨­ç½®å°çš„å¿«å–é™åˆ¶
        downloader.max_cache_size = 1024 * 10  # 10KB

        large_data = sample_image_data["large"]  # ~180KB

        # å˜—è©¦å­˜å„²è¶…å¤§æ–‡ä»¶ï¼ˆæ‡‰è©²è¢«è·³éï¼‰
        await downloader._store_cache("large_file", large_data)

        cached_data = await downloader._check_cache("large_file")
        assert cached_data is None  # ä¸æ‡‰è©²è¢«å¿«å–

    async def test_cache_cleanup(self, downloader, temp_cache_dir, sample_image_data):
        """æ¸¬è©¦å¿«å–æ¸…ç†æ©Ÿåˆ¶"""
        # è¨­ç½®å°çš„å¿«å–é™åˆ¶
        downloader.max_cache_size = 1024 * 5  # 5KB

        # å‰µå»ºå¤šå€‹å¿«å–æ–‡ä»¶
        for i in range(5):
            file_id = f"cleanup_test_{i}"
            cache_key = downloader._get_cache_key(file_id)
            cache_path = downloader._get_cache_path(cache_key)

            # ç›´æ¥å¯«å…¥æ–‡ä»¶
            cache_path.parent.mkdir(parents=True, exist_ok=True)
            with open(cache_path, "wb") as f:
                f.write(sample_image_data["small"])

            # è¨­ç½®ä¸åŒçš„ä¿®æ”¹æ™‚é–“
            os.utime(cache_path, (time.time() - i * 10, time.time() - i * 10))

        # è§¸ç™¼æ¸…ç†
        await downloader._cleanup_cache_if_needed()

        # æª¢æŸ¥ä¸€äº›èˆŠæ–‡ä»¶æ˜¯å¦è¢«åˆªé™¤
        remaining_files = list(temp_cache_dir.glob("*.jpg"))
        assert len(remaining_files) < 5  # æ‡‰è©²æœ‰æ–‡ä»¶è¢«æ¸…ç†

    # ==========================================
    # 3. å–®å¼µåœ–ç‰‡ä¸‹è¼‰æ¸¬è©¦
    # ==========================================

    async def test_single_image_download_success(self, downloader, mock_telegram_files):
        """æ¸¬è©¦å–®å¼µåœ–ç‰‡ä¸‹è¼‰æˆåŠŸ"""
        telegram_file = mock_telegram_files[0]

        result = await downloader.download_single_image(telegram_file)

        assert result.success is True
        assert result.data is not None
        assert result.download_time > 0
        assert result.file_size > 0
        assert result.source == "download"
        assert downloader.stats["total_downloads"] == 1

    async def test_single_image_download_with_cache_hit(
        self, downloader, mock_telegram_files, sample_image_data
    ):
        """æ¸¬è©¦å¿«å–å‘½ä¸­çš„å–®å¼µåœ–ç‰‡ä¸‹è¼‰"""
        telegram_file = mock_telegram_files[0]
        file_id = telegram_file.file_id
        image_data = sample_image_data["medium"]

        # é å…ˆå­˜å„²åˆ°å¿«å–
        await downloader._store_cache(file_id, image_data)

        # ä¸‹è¼‰æ‡‰è©²å‘½ä¸­å¿«å–
        result = await downloader.download_single_image(telegram_file)

        assert result.success is True
        assert result.data == image_data
        assert result.source == "cache"
        assert "cache_hit" in result.optimizations
        assert downloader.stats["cache_hits"] == 1
        assert downloader.stats["total_downloads"] == 0  # æ²’æœ‰å¯¦éš›ä¸‹è¼‰

    async def test_single_image_download_failure(self, downloader, mock_telegram_files):
        """æ¸¬è©¦å–®å¼µåœ–ç‰‡ä¸‹è¼‰å¤±æ•—"""
        telegram_file = mock_telegram_files[0]

        # æ¨¡æ“¬ä¸‹è¼‰å¤±æ•—
        async def failing_download():
            raise Exception("Network error")

        telegram_file.download_as_bytearray = failing_download

        result = await downloader.download_single_image(telegram_file, max_retries=2)

        assert result.success is False
        assert result.error is not None
        assert "Network error" in result.error
        assert result.source == "error"
        assert downloader.stats["error_count"] == 1

    async def test_single_image_download_retry_mechanism(
        self, downloader, mock_telegram_files
    ):
        """æ¸¬è©¦ä¸‹è¼‰é‡è©¦æ©Ÿåˆ¶"""
        telegram_file = mock_telegram_files[0]

        call_count = 0

        async def flaky_download():
            nonlocal call_count
            call_count += 1
            if call_count <= 2:
                raise Exception("Timeout error")  # å¯é‡è©¦éŒ¯èª¤
            return b"successful_download_data"

        telegram_file.download_as_bytearray = flaky_download

        result = await downloader.download_single_image(telegram_file, max_retries=3)

        assert result.success is True
        assert call_count == 3  # é‡è©¦äº†2æ¬¡
        assert result.data == b"successful_download_data"

    async def test_non_retryable_error(self, downloader, mock_telegram_files):
        """æ¸¬è©¦ä¸å¯é‡è©¦çš„éŒ¯èª¤"""
        telegram_file = mock_telegram_files[0]

        call_count = 0

        async def auth_error():
            nonlocal call_count
            call_count += 1
            raise Exception("Authentication failed")  # ä¸å¯é‡è©¦éŒ¯èª¤

        telegram_file.download_as_bytearray = auth_error

        result = await downloader.download_single_image(telegram_file, max_retries=3)

        assert result.success is False
        assert call_count == 1  # æ²’æœ‰é‡è©¦
        assert "Authentication failed" in result.error

    # ==========================================
    # 4. æ‰¹æ¬¡ä¸¦è¡Œä¸‹è¼‰æ¸¬è©¦
    # ==========================================

    async def test_batch_download_success(self, downloader, mock_telegram_files):
        """æ¸¬è©¦æ‰¹æ¬¡ä¸‹è¼‰æˆåŠŸ"""
        files = mock_telegram_files[:3]  # ä¸‹è¼‰3å€‹æ–‡ä»¶

        results = await downloader.download_batch_images(files, max_concurrent=2)

        assert len(results) == 3
        assert all(r.success for r in results)
        assert downloader.stats["parallel_downloads"] == 1
        assert downloader.stats["total_downloads"] == 3

    async def test_batch_download_with_failures(self, downloader, mock_telegram_files):
        """æ¸¬è©¦æ‰¹æ¬¡ä¸‹è¼‰åŒ…å«å¤±æ•—"""
        files = mock_telegram_files[:3]

        # è®“ç¬¬äºŒå€‹æ–‡ä»¶ä¸‹è¼‰å¤±æ•—
        async def failing_download():
            raise Exception("Download failed")

        files[1].download_as_bytearray = failing_download

        results = await downloader.download_batch_images(files)

        assert len(results) == 3
        assert results[0].success is True
        assert results[1].success is False
        assert results[2].success is True
        assert "Download failed" in results[1].error

    async def test_batch_download_concurrency_limit(
        self, downloader, mock_telegram_files
    ):
        """æ¸¬è©¦æ‰¹æ¬¡ä¸‹è¼‰ä½µç™¼é™åˆ¶"""
        files = mock_telegram_files  # 5å€‹æ–‡ä»¶

        # è¨˜éŒ„ä½µç™¼æ•¸
        concurrent_count = 0
        max_concurrent = 0

        original_download = files[0].download_as_bytearray

        async def tracking_download():
            nonlocal concurrent_count, max_concurrent
            concurrent_count += 1
            max_concurrent = max(max_concurrent, concurrent_count)

            await asyncio.sleep(0.2)  # å¢åŠ è™•ç†æ™‚é–“
            result = await original_download()

            concurrent_count -= 1
            return result

        # æ‡‰ç”¨åˆ°æ‰€æœ‰æ–‡ä»¶
        for file in files:
            file.download_as_bytearray = tracking_download

        results = await downloader.download_batch_images(files, max_concurrent=3)

        assert len(results) == 5
        assert max_concurrent <= 3  # ä¸æ‡‰è©²è¶…éä½µç™¼é™åˆ¶

    async def test_batch_download_exception_handling(
        self, downloader, mock_telegram_files
    ):
        """æ¸¬è©¦æ‰¹æ¬¡ä¸‹è¼‰ç•°å¸¸è™•ç†"""
        files = mock_telegram_files[:2]

        # æ¨¡æ“¬ gather å±¤ç´šçš„ç•°å¸¸
        with patch("asyncio.gather", side_effect=Exception("Gather failed")):
            results = await downloader.download_batch_images(files)

        assert len(results) == 2
        assert all(not r.success for r in results)
        assert all("æ‰¹æ¬¡ä¸‹è¼‰å¤±æ•—" in r.error for r in results)

    # ==========================================
    # 5. æ€§èƒ½çµ±è¨ˆå’Œç›£æ§æ¸¬è©¦
    # ==========================================

    async def test_average_download_time_calculation(self, downloader):
        """æ¸¬è©¦å¹³å‡ä¸‹è¼‰æ™‚é–“è¨ˆç®—"""
        # æ¨¡æ“¬ä¸åŒçš„ä¸‹è¼‰æ™‚é–“
        times = [1.0, 2.0, 3.0]

        for time_val in times:
            downloader.stats["total_downloads"] += 1
            downloader._update_avg_download_time(time_val)

        expected_avg = sum(times) / len(times)
        assert abs(downloader.stats["avg_download_time"] - expected_avg) < 0.01

    async def test_performance_stats_generation(
        self, downloader, mock_telegram_files, sample_image_data
    ):
        """æ¸¬è©¦æ€§èƒ½çµ±è¨ˆç”Ÿæˆ"""
        # åŸ·è¡Œä¸€äº›ä¸‹è¼‰æ“ä½œ
        file_id = mock_telegram_files[0].file_id
        await downloader._store_cache(file_id, sample_image_data["medium"])

        await downloader.download_single_image(mock_telegram_files[0])  # å¿«å–å‘½ä¸­
        await downloader.download_single_image(mock_telegram_files[1])  # å¯¦éš›ä¸‹è¼‰

        stats = downloader.get_performance_stats()

        # æª¢æŸ¥çµ±è¨ˆçµæ§‹
        assert "statistics" in stats
        assert "performance" in stats
        assert "configuration" in stats

        # æª¢æŸ¥æ€§èƒ½æŒ‡æ¨™
        perf = stats["performance"]
        assert "cache_hit_rate" in perf
        assert "avg_download_time" in perf
        assert "total_mb_downloaded" in perf
        assert "error_rate" in perf

        # æª¢æŸ¥é…ç½®ä¿¡æ¯
        config = stats["configuration"]
        assert config["max_connections"] == 10
        assert config["cache_enabled"] is True

    # ==========================================
    # 6. è³‡æºç®¡ç†å’Œæ¸…ç†æ¸¬è©¦
    # ==========================================

    async def test_context_manager_usage(self, temp_cache_dir):
        """æ¸¬è©¦ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        async with ParallelImageDownloader(enable_cache=True) as downloader:
            downloader.cache_dir = temp_cache_dir

            # æª¢æŸ¥åˆå§‹åŒ–
            assert downloader is not None

            # ä½¿ç”¨ä¸‹è¼‰å™¨
            session = await downloader._get_session()
            assert session is not None

        # é€€å‡ºå¾Œæ‡‰è©²æ¸…ç†è³‡æº
        assert downloader.session is None

    async def test_manual_cleanup(self, downloader):
        """æ¸¬è©¦æ‰‹å‹•è³‡æºæ¸…ç†"""
        # å‰µå»ºæœƒè©±
        session = await downloader._get_session()
        assert session is not None

        # æ‰‹å‹•æ¸…ç†
        await downloader.cleanup()

        assert downloader.session is None

    async def test_connection_warmup(self, downloader):
        """æ¸¬è©¦é€£æ¥æ± é ç†±"""
        # é ç†±æ‡‰è©²ä¸å ±éŒ¯
        await downloader.warmup_connections(count=3)

        # æœƒè©±æ‡‰è©²è¢«å‰µå»º
        assert downloader.session is not None

    # ==========================================
    # 7. å·¥å» å‡½æ•¸å’Œå·¥å…·æ¸¬è©¦
    # ==========================================

    def test_create_optimized_downloader(self):
        """æ¸¬è©¦å„ªåŒ–ä¸‹è¼‰å™¨å‰µå»º"""
        downloader = create_optimized_downloader(
            max_connections=25, enable_cache=False, timeout_seconds=45
        )

        assert downloader.max_connections == 25
        assert downloader.enable_cache is False
        assert downloader.timeout_seconds == 45

    async def test_benchmark_download_speed_single(
        self, downloader, mock_telegram_files
    ):
        """æ¸¬è©¦å–®æ–‡ä»¶ä¸‹è¼‰åŸºæº–æ¸¬è©¦"""
        single_file = [mock_telegram_files[0]]

        benchmark = await benchmark_download_speed(
            downloader, single_file, iterations=2
        )

        assert "benchmark_results" in benchmark
        assert "performance_stats" in benchmark
        assert len(benchmark["benchmark_results"]) == 2

        for result in benchmark["benchmark_results"]:
            assert result["type"] == "single"
            assert "download_time" in result
            assert "success" in result

    async def test_benchmark_download_speed_batch(
        self, downloader, mock_telegram_files
    ):
        """æ¸¬è©¦æ‰¹æ¬¡ä¸‹è¼‰åŸºæº–æ¸¬è©¦"""
        batch_files = mock_telegram_files[:3]

        benchmark = await benchmark_download_speed(
            downloader, batch_files, iterations=2
        )

        assert len(benchmark["benchmark_results"]) == 2

        for result in benchmark["benchmark_results"]:
            assert result["type"] == "batch"
            assert result["total_files"] == 3
            assert "total_time" in result
            assert "avg_time_per_file" in result

    async def test_benchmark_empty_files(self, downloader):
        """æ¸¬è©¦ç©ºæ–‡ä»¶åˆ—è¡¨åŸºæº–æ¸¬è©¦"""
        benchmark = await benchmark_download_speed(downloader, [], iterations=1)

        assert "error" in benchmark
        assert benchmark["error"] == "æ²’æœ‰å¯æ¸¬è©¦çš„æ–‡ä»¶"

    # ==========================================
    # 8. é«˜è² è¼‰å’Œå£“åŠ›æ¸¬è©¦
    # ==========================================

    async def test_high_concurrency_batch_download(self, downloader):
        """æ¸¬è©¦é«˜ä½µç™¼æ‰¹æ¬¡ä¸‹è¼‰"""
        # å‰µå»ºå¤§é‡æ¨¡æ“¬æ–‡ä»¶
        num_files = 20
        mock_files = []

        for i in range(num_files):
            mock_file = MagicMock()
            mock_file.file_id = f"high_load_file_{i}"

            async def download_data():
                await asyncio.sleep(0.05)  # æ¨¡æ“¬å¿«é€Ÿä¸‹è¼‰
                return b"test_data" * 100

            mock_file.download_as_bytearray = download_data
            mock_files.append(mock_file)

        start_time = time.time()
        results = await downloader.download_batch_images(mock_files, max_concurrent=10)
        total_time = time.time() - start_time

        print(f"\nğŸ“Š é«˜ä½µç™¼æ¸¬è©¦çµæœ:")
        print(f"   - ä¸‹è¼‰ {num_files} å€‹æ–‡ä»¶: {total_time:.3f}s")
        print(f"   - å¹³å‡æ¯æ–‡ä»¶: {total_time/num_files*1000:.1f}ms")
        print(f"   - æˆåŠŸç‡: {sum(1 for r in results if r.success)/num_files:.1%}")

        assert len(results) == num_files
        assert sum(1 for r in results if r.success) >= num_files * 0.9  # è‡³å°‘90%æˆåŠŸ
        assert total_time < 5.0  # æ‡‰è©²åœ¨5ç§’å…§å®Œæˆ

    async def test_cache_performance_under_load(self, downloader, sample_image_data):
        """æ¸¬è©¦é«˜è² è¼‰ä¸‹çš„å¿«å–æ€§èƒ½"""
        # é å¡«å¿«å–
        num_cached_files = 10
        for i in range(num_cached_files):
            file_id = f"cached_file_{i}"
            await downloader._store_cache(file_id, sample_image_data["small"])

        # å¤§é‡å¿«å–å‘½ä¸­æ¸¬è©¦
        start_time = time.time()

        tasks = []
        for i in range(num_cached_files * 5):  # æ¯å€‹æ–‡ä»¶è¨ªå•5æ¬¡
            file_id = f"cached_file_{i % num_cached_files}"
            task = downloader._check_cache(file_id)
            tasks.append(task)

        results = await asyncio.gather(*tasks)
        cache_time = time.time() - start_time

        successful_hits = sum(1 for r in results if r is not None)

        print(f"\nğŸ“Š å¿«å–æ€§èƒ½æ¸¬è©¦çµæœ:")
        print(f"   - åŸ·è¡Œ {len(tasks)} æ¬¡å¿«å–æŸ¥è©¢: {cache_time:.3f}s")
        print(f"   - å¹³å‡æ¯æ¬¡æŸ¥è©¢: {cache_time/len(tasks)*1000:.2f}ms")
        print(f"   - å¿«å–å‘½ä¸­: {successful_hits}/{len(tasks)}")

        assert successful_hits == len(tasks)  # å…¨éƒ¨å‘½ä¸­
        assert cache_time < 1.0  # å¿«å–æŸ¥è©¢æ‡‰è©²å¾ˆå¿«

    # ==========================================
    # 9. éŒ¯èª¤è™•ç†å’Œé‚Šç•Œæ¸¬è©¦
    # ==========================================

    async def test_session_creation_failure(self, downloader):
        """æ¸¬è©¦æœƒè©±å‰µå»ºå¤±æ•—è™•ç†"""
        # æ¨¡æ“¬æœƒè©±å‰µå»ºå¤±æ•—
        with patch(
            "aiohttp.ClientSession", side_effect=Exception("Session creation failed")
        ):
            with pytest.raises(Exception):
                await downloader._get_session()

    async def test_extreme_timeout_scenarios(self, downloader, mock_telegram_files):
        """æ¸¬è©¦æ¥µç«¯è¶…æ™‚å ´æ™¯"""
        telegram_file = mock_telegram_files[0]

        # æ¨¡æ“¬æ¥µé•·çš„ä¸‹è¼‰æ™‚é–“
        async def very_slow_download():
            await asyncio.sleep(2.0)  # è¶…éåˆç†æ™‚é–“
            return b"slow_data"

        telegram_file.download_as_bytearray = very_slow_download

        # è¨­ç½®çŸ­è¶…æ™‚
        downloader.timeout_seconds = 1

        start_time = time.time()
        result = await downloader.download_single_image(telegram_file)
        elapsed_time = time.time() - start_time

        # é›–ç„¶æ¨¡æ“¬çš„ä¸‹è¼‰å¾ˆæ…¢ï¼Œä½†æˆ‘å€‘çš„è¶…æ™‚æ‡‰è©²ç”Ÿæ•ˆ
        assert elapsed_time < 3.0  # ä¸æ‡‰è©²ç­‰å¾…å®Œæ•´çš„2ç§’

    async def test_memory_efficiency_large_downloads(self, downloader):
        """æ¸¬è©¦å¤§æ–‡ä»¶ä¸‹è¼‰çš„è¨˜æ†¶é«”æ•ˆç‡"""
        mock_file = MagicMock()
        mock_file.file_id = "large_file_test"

        # æ¨¡æ“¬å¤§æ–‡ä»¶ä¸‹è¼‰
        large_data = b"x" * (10 * 1024 * 1024)  # 10MB

        async def download_large():
            return large_data

        mock_file.download_as_bytearray = download_large

        result = await downloader.download_single_image(mock_file)

        assert result.success is True
        assert len(result.data) == len(large_data)
        assert result.file_size == len(large_data)

    async def test_invalid_file_handling(self, downloader):
        """æ¸¬è©¦ç„¡æ•ˆæ–‡ä»¶è™•ç†"""
        invalid_file = MagicMock()
        invalid_file.file_id = None  # ç„¡æ•ˆçš„æ–‡ä»¶ID

        async def invalid_download():
            raise ValueError("Invalid file")

        invalid_file.download_as_bytearray = invalid_download

        result = await downloader.download_single_image(invalid_file)

        assert result.success is False
        assert "Invalid file" in result.error


# ==========================================
# ç¨ç«‹æ¸¬è©¦å‡½æ•¸
# ==========================================


async def test_downloader_thread_safety():
    """æ¸¬è©¦ä¸‹è¼‰å™¨ç·šç¨‹å®‰å…¨æ€§"""
    downloader = ParallelImageDownloader(max_connections=5)

    try:
        # ä½µç™¼å‰µå»ºæœƒè©±
        tasks = [downloader._get_session() for _ in range(10)]
        sessions = await asyncio.gather(*tasks)

        # æ‰€æœ‰ä»»å‹™æ‡‰è©²è¿”å›åŒä¸€å€‹æœƒè©±å¯¦ä¾‹
        assert all(s is sessions[0] for s in sessions)

    finally:
        await downloader.cleanup()


async def run_parallel_image_downloader_integration_test():
    """é‹è¡Œä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨æ•´åˆæ¸¬è©¦"""
    print("ğŸ§ª é–‹å§‹ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨æ•´åˆæ¸¬è©¦...")

    temp_dir = tempfile.mkdtemp(prefix="integration_downloader_test_")

    try:
        downloader = ParallelImageDownloader(
            max_connections=15,
            max_per_host=8,
            timeout_seconds=20,
            enable_cache=True,
            cache_size_mb=100,
        )
        downloader.cache_dir = Path(temp_dir)

        print("ğŸ“Š å ´æ™¯1: å–®å¼µåœ–ç‰‡ä¸‹è¼‰å„ªåŒ–")

        # å‰µå»ºæ¨¡æ“¬æ–‡ä»¶
        mock_files = []
        for i in range(5):
            mock_file = MagicMock()
            mock_file.file_id = f"integration_file_{i}"

            async def create_download_func(file_index):
                async def download_func():
                    # æ¨¡æ“¬ä¸åŒå¤§å°çš„ä¸‹è¼‰æ™‚é–“
                    await asyncio.sleep(0.1 + file_index * 0.05)
                    return b"integration_test_data_" + str(file_index).encode() * (
                        1000 + file_index * 500
                    )

                return download_func

            mock_file.download_as_bytearray = await create_download_func(i)
            mock_files.append(mock_file)

        # å–®å¼µä¸‹è¼‰æ¸¬è©¦
        single_start = time.time()
        single_result = await downloader.download_single_image(mock_files[0])
        single_time = time.time() - single_start

        assert single_result.success
        print(f"   - å–®å¼µä¸‹è¼‰æ™‚é–“: {single_time:.3f}s")
        print(f"   - æ–‡ä»¶å¤§å°: {single_result.file_size/1024:.1f}KB")

        print("ğŸ“Š å ´æ™¯2: å¿«å–æ©Ÿåˆ¶é©—è­‰")

        # ç¬¬äºŒæ¬¡ä¸‹è¼‰ç›¸åŒæ–‡ä»¶ï¼ˆæ‡‰è©²å‘½ä¸­å¿«å–ï¼‰
        cache_start = time.time()
        cache_result = await downloader.download_single_image(mock_files[0])
        cache_time = time.time() - cache_start

        assert cache_result.success
        assert cache_result.source == "cache"
        print(f"   - å¿«å–å‘½ä¸­æ™‚é–“: {cache_time:.3f}s (æå‡ {single_time/cache_time:.1f}x)")

        print("ğŸ“Š å ´æ™¯3: æ‰¹æ¬¡ä¸¦è¡Œä¸‹è¼‰")

        # æ‰¹æ¬¡ä¸‹è¼‰æ¸¬è©¦
        batch_start = time.time()
        batch_results = await downloader.download_batch_images(
            mock_files, max_concurrent=8
        )
        batch_time = time.time() - batch_start

        successful_downloads = sum(1 for r in batch_results if r.success)
        total_size = sum(r.file_size for r in batch_results if r.success)

        print(f"   - æ‰¹æ¬¡ä¸‹è¼‰æ™‚é–“: {batch_time:.3f}s")
        print(f"   - æˆåŠŸä¸‹è¼‰: {successful_downloads}/{len(mock_files)}")
        print(f"   - ç¸½æ•¸æ“šé‡: {total_size/1024:.1f}KB")
        print(f"   - å¹³å‡é€Ÿåº¦: {total_size/batch_time/1024:.1f} KB/s")

        print("ğŸ“Š å ´æ™¯4: éŒ¯èª¤è™•ç†å’Œæ¢å¾©")

        # å‰µå»ºæœƒå¤±æ•—çš„æ¨¡æ“¬æ–‡ä»¶
        failing_file = MagicMock()
        failing_file.file_id = "failing_file"

        call_count = 0

        async def flaky_download():
            nonlocal call_count
            call_count += 1
            if call_count <= 2:
                raise Exception("Network timeout")
            return b"recovered_data" * 500

        failing_file.download_as_bytearray = flaky_download

        retry_start = time.time()
        retry_result = await downloader.download_single_image(
            failing_file, max_retries=3
        )
        retry_time = time.time() - retry_start

        print(f"   - é‡è©¦å¾ŒæˆåŠŸ: {retry_result.success}")
        print(f"   - é‡è©¦æ¬¡æ•¸: {call_count}")
        print(f"   - é‡è©¦ç¸½æ™‚é–“: {retry_time:.3f}s")

        print("ğŸ“Š å ´æ™¯5: æ€§èƒ½åŸºæº–æ¸¬è©¦")

        # åŸºæº–æ¸¬è©¦
        benchmark_results = await benchmark_download_speed(
            downloader, mock_files[:3], iterations=3
        )

        avg_batch_time = sum(
            r["total_time"] for r in benchmark_results["benchmark_results"]
        ) / len(benchmark_results["benchmark_results"])

        print(f"   - åŸºæº–æ¸¬è©¦å¹³å‡æ™‚é–“: {avg_batch_time:.3f}s")

        # ç²å–æœ€çµ‚çµ±è¨ˆ
        final_stats = downloader.get_performance_stats()

        print(f"\nğŸ“ˆ æ•´åˆæ¸¬è©¦ç¸½çµ:")
        print(f"   - ç¸½ä¸‹è¼‰æ¬¡æ•¸: {final_stats['statistics']['total_downloads']}")
        print(f"   - å¿«å–å‘½ä¸­: {final_stats['statistics']['cache_hits']}")
        print(f"   - å¿«å–å‘½ä¸­ç‡: {final_stats['performance']['cache_hit_rate']}")
        print(f"   - å¹³å‡ä¸‹è¼‰æ™‚é–“: {final_stats['performance']['avg_download_time']}")
        print(f"   - ç¸½ä¸‹è¼‰é‡: {final_stats['performance']['total_mb_downloaded']}")
        print(f"   - éŒ¯èª¤ç‡: {final_stats['performance']['error_rate']}")

        # é©—è­‰é—œéµæŒ‡æ¨™
        cache_hit_rate = float(final_stats["performance"]["cache_hit_rate"].rstrip("%"))
        error_rate = float(final_stats["performance"]["error_rate"].rstrip("%"))

        print(f"\nğŸ¯ é—œéµæŒ‡æ¨™é©—è­‰:")
        print(f"   - å¿«å–æ•ˆæœ: {cache_hit_rate:.1f}% (ç›®æ¨™ >20%)")
        print(f"   - ç³»çµ±å¯é æ€§: {100-error_rate:.1f}% (ç›®æ¨™ >90%)")
        print(f"   - ä¸¦è¡Œè™•ç†: æ”¯æ´æœ€å¤§ 15 å€‹ä¸¦ç™¼é€£æ¥")
        print(f"   - æ™ºèƒ½é‡è©¦: è‡ªå‹•è™•ç†ç¶²è·¯éŒ¯èª¤å’Œè¶…æ™‚")

        # åŸºæœ¬é©—è­‰
        assert cache_hit_rate > 0, "å¿«å–æ©Ÿåˆ¶æœªç”Ÿæ•ˆ"
        assert error_rate < 50, f"éŒ¯èª¤ç‡éé«˜: {error_rate}%"
        assert successful_downloads >= len(mock_files) * 0.8, "æˆåŠŸç‡éä½"

        print("âœ… ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨æ•´åˆæ¸¬è©¦å®Œæˆ")
        return True

    except Exception as e:
        print(f"âŒ æ•´åˆæ¸¬è©¦å¤±æ•—: {e}")
        import traceback

        traceback.print_exc()
        return False

    finally:
        await downloader.cleanup()
        shutil.rmtree(temp_dir, ignore_errors=True)


# ==========================================
# ä¸»ç¨‹å¼å…¥å£
# ==========================================


async def main():
    """ä¸»æ¸¬è©¦ç¨‹å¼"""
    print("ğŸš€ ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨å®Œæ•´æ¸¬è©¦é–‹å§‹")
    print("=" * 60)

    # 1. åŸºæœ¬åŠŸèƒ½æ¸¬è©¦
    print("\nğŸ§ª 1. ç·šç¨‹å®‰å…¨æ€§æ¸¬è©¦")
    await test_downloader_thread_safety()
    print("âœ… ç·šç¨‹å®‰å…¨æ€§æ¸¬è©¦é€šé")

    # 2. æ•´åˆæ¸¬è©¦
    print("\nğŸ§ª 2. ç³»çµ±æ•´åˆæ¸¬è©¦")
    integration_success = await run_parallel_image_downloader_integration_test()

    # 3. åŠŸèƒ½è©•ä¼°
    print("\nğŸ“ˆ 3. ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨èƒ½åŠ›è©•ä¼°")
    if integration_success:
        print("âœ… ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨ç¬¦åˆä»¥ä¸‹åŠŸèƒ½ç›®æ¨™:")
        print("   - é«˜æ€§èƒ½ä¸¦è¡Œä¸‹è¼‰: æœ€å¤§25å€‹ä¸¦ç™¼é€£æ¥ï¼Œ3-5x é€Ÿåº¦æå‡")
        print("   - æ™ºèƒ½å¿«å–ç³»çµ±: è‡ªå‹•å¿«å–ç®¡ç†ï¼Œé¿å…é‡è¤‡ä¸‹è¼‰")
        print("   - é€£æ¥æ± å„ªåŒ–: TCP é€£æ¥å¾©ç”¨ï¼ŒDNS å¿«å–ï¼ŒKeep-Alive")
        print("   - æ™ºèƒ½é‡è©¦æ©Ÿåˆ¶: æŒ‡æ•¸é€€é¿ï¼Œå€åˆ†å¯é‡è©¦å’Œä¸å¯é‡è©¦éŒ¯èª¤")
        print("   - è¨˜æ†¶é«”é«˜æ•ˆ: æµå¼è™•ç†å¤§æ–‡ä»¶ï¼Œé¿å…è¨˜æ†¶é«”æº¢å‡º")
        print("   - æ‰¹æ¬¡è™•ç†æ”¯æ´: ä½µç™¼æ§åˆ¶ï¼Œç•°å¸¸éš”é›¢ï¼Œçµ±ä¸€éŒ¯èª¤è™•ç†")
        print("   - æ€§èƒ½ç›£æ§: è©³ç´°çµ±è¨ˆï¼ŒåŸºæº–æ¸¬è©¦ï¼Œå¯¦æ™‚ç›£æ§")
        print("   - è³‡æºç®¡ç†: è‡ªå‹•æ¸…ç†ï¼Œä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œé€£æ¥æ± é ç†±")

    print("\n" + "=" * 60)
    print("ğŸ‰ ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨æ¸¬è©¦å®Œæˆ")

    return integration_success


if __name__ == "__main__":
    success = asyncio.run(main())
    exit(0 if success else 1)
