"""
æœ€ä½³åŒ– AI æœå‹™æ•´åˆç¯„ä¾‹ - AI Engineer å¯¦ä½œ
å±•ç¤ºå¦‚ä½•åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­æ•´åˆæ‰€æœ‰ AI æœ€ä½³åŒ–çµ„ä»¶
"""

import asyncio
import os
import sys
from datetime import datetime
from typing import Any, Dict, List

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from src.namecard.infrastructure.ai.optimized_ai_service import (
    ProcessingPriority,
    create_optimized_ai_service,
)


class OptimizedNameCardBot:
    """æœ€ä½³åŒ–åç‰‡ Bot - ç”Ÿç”¢ç’°å¢ƒæ•´åˆç¯„ä¾‹"""

    def __init__(self):
        self.ai_service = None
        self.processing_stats = {
            "total_processed": 0,
            "cache_hits": 0,
            "errors": 0,
            "start_time": datetime.now(),
        }

    async def initialize(self):
        """åˆå§‹åŒ– Bot å’Œ AI æœå‹™"""
        print("ğŸš€ åˆå§‹åŒ–æœ€ä½³åŒ–åç‰‡ Bot...")

        # å»ºç«‹ AI æœå‹™ï¼ˆè‡ªå‹•å•Ÿå‹•ï¼‰
        self.ai_service = await create_optimized_ai_service(
            max_concurrent=15,  # æ”¯æ´15å€‹ä½µç™¼è«‹æ±‚
            cache_memory_mb=200,  # 200MB è¨˜æ†¶é«”å¿«å–
            cache_disk_mb=1000,  # 1GB ç£ç¢Ÿå¿«å–
            auto_start=True,
        )

        print("âœ… Bot åˆå§‹åŒ–å®Œæˆ")

    async def process_single_namecard(
        self,
        image_bytes: bytes,
        user_id: str,
        priority: ProcessingPriority = ProcessingPriority.NORMAL,
    ) -> Dict[str, Any]:
        """è™•ç†å–®å¼µåç‰‡ - æœ€ä½³åŒ–ç‰ˆæœ¬"""

        print(f"ğŸ“¸ è™•ç†ç”¨æˆ¶ {user_id} çš„åç‰‡...")

        # ä½¿ç”¨æœ€ä½³åŒ–æœå‹™è™•ç†
        result, metadata = await self.ai_service.process_image(
            image_bytes=image_bytes,
            priority=priority,
            enable_cache=True,
            timeout=25.0,  # 25ç§’è¶…æ™‚
            user_id=user_id,
        )

        # æ›´æ–°çµ±è¨ˆ
        self.processing_stats["total_processed"] += 1
        if metadata["cache_hit"]:
            self.processing_stats["cache_hits"] += 1
        if not metadata["success"]:
            self.processing_stats["errors"] += 1

        # ç”Ÿæˆç”¨æˆ¶å‹å–„å›æ‡‰
        response = self._generate_user_response(result, metadata)

        print(
            f"âœ… è™•ç†å®Œæˆ: {user_id} "
            f"({'å¿«å–å‘½ä¸­' if metadata['cache_hit'] else 'æ–°è™•ç†'}) "
            f"({metadata.get('processing_time', 0):.2f}s)"
        )

        return {
            "user_response": response,
            "processing_metadata": metadata,
            "result": result,
        }

    async def process_batch_namecards(
        self, image_batch: List[bytes], user_id: str
    ) -> Dict[str, Any]:
        """æ‰¹æ¬¡è™•ç†åç‰‡ - æœ€ä½³åŒ–ç‰ˆæœ¬"""

        print(f"ğŸ“¸ æ‰¹æ¬¡è™•ç†ç”¨æˆ¶ {user_id} çš„ {len(image_batch)} å¼µåç‰‡...")

        # ä½¿ç”¨æœ€ä½³åŒ–æ‰¹æ¬¡è™•ç†
        results, batch_metadata = await self.ai_service.process_batch(
            image_batch=image_batch,
            max_concurrent=8,  # æ‰¹æ¬¡å…§æœ€å¤§ä½µç™¼
            enable_cache=True,
            user_id=user_id,
        )

        # æ›´æ–°çµ±è¨ˆ
        self.processing_stats["total_processed"] += len(image_batch)
        self.processing_stats["cache_hits"] += batch_metadata["processing_summary"][
            "cached"
        ]
        self.processing_stats["errors"] += batch_metadata["processing_summary"][
            "failed"
        ]

        # ç”Ÿæˆæ‰¹æ¬¡æ‘˜è¦
        summary = self._generate_batch_summary(results, batch_metadata)

        print(
            f"âœ… æ‰¹æ¬¡è™•ç†å®Œæˆ: {user_id} "
            f"({batch_metadata['processing_summary']['successful']} æˆåŠŸ, "
            f"{batch_metadata['processing_summary']['failed']} å¤±æ•—, "
            f"{batch_metadata.get('total_processing_time', 0):.2f}s)"
        )

        return {
            "batch_summary": summary,
            "batch_metadata": batch_metadata,
            "individual_results": results,
        }

    def _generate_user_response(
        self, result: Dict[str, Any], metadata: Dict[str, Any]
    ) -> str:
        """ç”Ÿæˆç”¨æˆ¶å‹å–„çš„å›æ‡‰è¨Šæ¯"""

        if "error" in result:
            return f"âŒ åç‰‡è™•ç†å¤±æ•—: {result['error']}\nè«‹é‡æ–°æ‹æ”æˆ–ç¨å¾Œå†è©¦ã€‚"

        card_count = result.get("card_count", 0)
        overall_quality = result.get("overall_quality", "unknown")

        # åŸºæœ¬å›æ‡‰
        if card_count == 0:
            return "ğŸ“¸ æœªæª¢æ¸¬åˆ°åç‰‡ï¼Œè«‹ç¢ºèªåœ–ç‰‡æ¸…æ™°ä¸¦é‡æ–°æ‹æ”ã€‚"

        elif card_count == 1:
            card = result["cards"][0]
            confidence = card.get("confidence_score", 0)

            response = f"âœ… åç‰‡è­˜åˆ¥å®Œæˆï¼\n"
            response += f"ğŸ‘¤ å§“å: {card.get('name', 'æœªè­˜åˆ¥')}\n"
            response += f"ğŸ¢ å…¬å¸: {card.get('company', 'æœªè­˜åˆ¥')}\n"

            if card.get("title"):
                response += f"ğŸ’¼ è·ç¨±: {card['title']}\n"
            if card.get("email"):
                response += f"ğŸ“§ Email: {card['email']}\n"
            if card.get("phone"):
                response += f"ğŸ“± é›»è©±: {card['phone']}\n"

            # å“è³ªæç¤º
            if overall_quality == "good":
                response += f"\nğŸ¯ è­˜åˆ¥å“è³ª: å„ªç§€ (ä¿¡å¿ƒåº¦: {confidence:.1%})"
            elif overall_quality == "partial":
                response += f"\nâš ï¸ è­˜åˆ¥å“è³ª: éƒ¨åˆ†è³‡è¨Šå¯èƒ½ä¸æº–ç¢º"
            else:
                response += f"\nâŒ è­˜åˆ¥å“è³ªè¼ƒå·®ï¼Œå»ºè­°é‡æ–°æ‹æ”"

            # å¿«å–æç¤º
            if metadata.get("cache_hit"):
                response += f"\nâš¡ å¿«é€Ÿè™•ç† (å¿«å–å‘½ä¸­)"

            return response

        else:
            # å¤šå¼µåç‰‡
            return (
                f"ğŸ“¸ æª¢æ¸¬åˆ° {card_count} å¼µåç‰‡\n"
                f"æ•´é«”å“è³ª: {overall_quality}\n"
                f"è«‹é¸æ“‡å¦‚ä½•è™•ç†é€™äº›åç‰‡ã€‚"
            )

    def _generate_batch_summary(
        self, results: List[Dict[str, Any]], batch_metadata: Dict[str, Any]
    ) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡è™•ç†æ‘˜è¦"""

        successful = batch_metadata["processing_summary"]["successful"]
        failed = batch_metadata["processing_summary"]["failed"]
        cached = batch_metadata["processing_summary"]["cached"]
        total_time = batch_metadata.get("total_processing_time", 0)

        summary = f"ğŸ“Š æ‰¹æ¬¡è™•ç†æ‘˜è¦\n"
        summary += f"âœ… æˆåŠŸè™•ç†: {successful} å¼µ\n"
        summary += f"âŒ è™•ç†å¤±æ•—: {failed} å¼µ\n"
        summary += f"âš¡ å¿«å–å‘½ä¸­: {cached} å¼µ\n"
        summary += f"â±ï¸ ç¸½è™•ç†æ™‚é–“: {total_time:.1f} ç§’\n"
        summary += f"ğŸš€ å¹³å‡è™•ç†æ™‚é–“: {total_time/len(results):.1f} ç§’/å¼µ"

        # å“è³ªçµ±è¨ˆ
        quality_stats = {"good": 0, "partial": 0, "poor": 0, "error": 0}
        for result in results:
            if "error" in result:
                quality_stats["error"] += 1
            else:
                quality = result.get("overall_quality", "unknown")
                if quality in quality_stats:
                    quality_stats[quality] += 1

        if any(quality_stats.values()):
            summary += f"\n\nğŸ“ˆ å“è³ªåˆ†å¸ƒ:\n"
            if quality_stats["good"]:
                summary += f"ğŸŸ¢ å„ªç§€: {quality_stats['good']} å¼µ\n"
            if quality_stats["partial"]:
                summary += f"ğŸŸ¡ éƒ¨åˆ†: {quality_stats['partial']} å¼µ\n"
            if quality_stats["poor"]:
                summary += f"ğŸ”´ è¼ƒå·®: {quality_stats['poor']} å¼µ\n"

        return summary

    async def get_service_dashboard(self) -> Dict[str, Any]:
        """ç²å–æœå‹™å„€è¡¨æ¿è³‡æ–™"""

        if not self.ai_service:
            return {"error": "AI æœå‹™æœªåˆå§‹åŒ–"}

        # ç²å–å„çµ„ä»¶ç‹€æ…‹
        service_status = await self.ai_service.get_service_status()
        health_check = await self.ai_service.health_check()

        # Bot çµ±è¨ˆ
        uptime = datetime.now() - self.processing_stats["start_time"]
        bot_stats = {
            **self.processing_stats,
            "uptime_hours": uptime.total_seconds() / 3600,
            "success_rate": (
                (
                    self.processing_stats["total_processed"]
                    - self.processing_stats["errors"]
                )
                / max(self.processing_stats["total_processed"], 1)
            ),
            "cache_hit_rate": (
                self.processing_stats["cache_hits"]
                / max(self.processing_stats["total_processed"], 1)
            ),
        }

        return {
            "bot_statistics": bot_stats,
            "service_status": service_status,
            "health_check": health_check,
            "optimization_recommendations": self.ai_service.get_optimization_recommendations(),
        }

    async def generate_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆæ•ˆèƒ½å ±å‘Š"""
        if not self.ai_service:
            return {"error": "AI æœå‹™æœªåˆå§‹åŒ–"}

        return await self.ai_service.get_performance_report(hours)

    async def optimize_service(self) -> Dict[str, Any]:
        """åŸ·è¡Œæœå‹™æœ€ä½³åŒ–"""
        if not self.ai_service:
            return {"error": "AI æœå‹™æœªåˆå§‹åŒ–"}

        return await self.ai_service.optimize_performance()

    async def shutdown(self):
        """é—œé–‰ Bot å’Œ AI æœå‹™"""
        print("ğŸ”„ é—œé–‰æœ€ä½³åŒ–åç‰‡ Bot...")

        if self.ai_service:
            await self.ai_service.stop_service()

        # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
        uptime = datetime.now() - self.processing_stats["start_time"]
        print(f"ğŸ“Š Bot é‹è¡Œçµ±è¨ˆ:")
        print(f"   - é‹è¡Œæ™‚é–“: {uptime}")
        print(f"   - è™•ç†ç¸½æ•¸: {self.processing_stats['total_processed']}")
        print(f"   - å¿«å–å‘½ä¸­: {self.processing_stats['cache_hits']}")
        print(f"   - éŒ¯èª¤æ•¸é‡: {self.processing_stats['errors']}")

        print("âœ… Bot å·²é—œé–‰")


async def main():
    """ä¸»è¦ç¤ºç¯„å‡½æ•¸"""
    print("ğŸš€ æœ€ä½³åŒ–åç‰‡ Bot ç¤ºç¯„")
    print("=" * 50)

    # å»ºç«‹ Bot
    bot = OptimizedNameCardBot()

    try:
        # åˆå§‹åŒ–
        await bot.initialize()

        # æ¨¡æ“¬è™•ç† (é€™è£¡éœ€è¦å¯¦éš›çš„åœ–ç‰‡è³‡æ–™)
        print("\nğŸ“¸ æ¨¡æ“¬åç‰‡è™•ç†...")

        # ç”Ÿæˆæ¸¬è©¦åœ–ç‰‡è³‡æ–™ (å¯¦éš›ä½¿ç”¨æ™‚æ›¿æ›ç‚ºçœŸå¯¦åœ–ç‰‡)
        test_image = b"fake image data for testing"

        # å–®å¼µè™•ç†ç¤ºç¯„
        print("\n1ï¸âƒ£ å–®å¼µåç‰‡è™•ç†ç¤ºç¯„:")
        single_result = await bot.process_single_namecard(
            image_bytes=test_image,
            user_id="test_user_001",
            priority=ProcessingPriority.HIGH,
        )
        print(f"å›æ‡‰: {single_result['user_response']}")

        # æ‰¹æ¬¡è™•ç†ç¤ºç¯„
        print("\n2ï¸âƒ£ æ‰¹æ¬¡åç‰‡è™•ç†ç¤ºç¯„:")
        batch_images = [test_image, test_image, test_image]  # 3å¼µæ¸¬è©¦åœ–ç‰‡
        batch_result = await bot.process_batch_namecards(
            image_batch=batch_images, user_id="test_user_002"
        )
        print(f"æ‰¹æ¬¡æ‘˜è¦: {batch_result['batch_summary']}")

        # æœå‹™å„€è¡¨æ¿
        print("\n3ï¸âƒ£ æœå‹™å„€è¡¨æ¿:")
        dashboard = await bot.get_service_dashboard()
        print(f"Bot çµ±è¨ˆ: è™•ç†ç¸½æ•¸ {dashboard['bot_statistics']['total_processed']}")
        print(f"æœå‹™å¥åº·: {dashboard['health_check']['status']}")

        # æ•ˆèƒ½æœ€ä½³åŒ–
        print("\n4ï¸âƒ£ åŸ·è¡Œæ•ˆèƒ½æœ€ä½³åŒ–:")
        optimization_result = await bot.optimize_service()
        print(f"æœ€ä½³åŒ–çµæœ: {optimization_result['success']}")
        if optimization_result["success"]:
            print(f"åŸ·è¡Œé …ç›®: {optimization_result['optimizations_performed']}")

        # ç­‰å¾…ä¸€æ®µæ™‚é–“ä»¥è§€å¯ŸèƒŒæ™¯ä»»å‹™
        print("\nâ±ï¸ é‹è¡Œ 30 ç§’ä»¥è§€å¯ŸèƒŒæ™¯ä»»å‹™...")
        await asyncio.sleep(30)

    except KeyboardInterrupt:
        print("\nâ¹ï¸ æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿ")
    except Exception as e:
        print(f"\nâŒ ç¤ºç¯„éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
    finally:
        # é—œé–‰æœå‹™
        await bot.shutdown()


if __name__ == "__main__":
    # è¨­å®šæ¸¬è©¦ç’°å¢ƒè®Šæ•¸ (å¯¦éš›éƒ¨ç½²æ™‚ä½¿ç”¨çœŸå¯¦ API Keys)
    os.environ.setdefault("GOOGLE_API_KEY", "test_api_key_1")
    os.environ.setdefault("GOOGLE_API_KEY_FALLBACK", "test_api_key_2")

    # é‹è¡Œç¤ºç¯„
    asyncio.run(main())
