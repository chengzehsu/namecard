"""
å„ªåŒ– AI æœå‹™ - çµ±ä¸€çš„é«˜æ•ˆèƒ½åç‰‡è™•ç†æœå‹™
"""

import asyncio
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

from src.namecard.core.services.async_batch_service import AsyncBatchService
from src.namecard.infrastructure.ai.async_card_processor import (
    AsyncCardProcessor,
    ProcessingMetadata,
    ProcessingPriority,
)
from src.namecard.infrastructure.storage.async_notion_client import AsyncNotionManager


class OptimizedAIService:
    """
    å„ªåŒ– AI æœå‹™ - æ•´åˆç•°æ­¥è™•ç†ã€æ‰¹æ¬¡è™•ç†å’Œæ™ºèƒ½å¿«å–
    æä¾›ç”Ÿç”¢ç´šåˆ¥çš„é«˜æ•ˆèƒ½åç‰‡è™•ç†èƒ½åŠ›
    """

    def __init__(
        self,
        max_concurrent_ai: int = 15,
        max_concurrent_notion: int = 10,
        max_global_concurrent: int = 50,
        enable_cache: bool = True,
        auto_notion_save: bool = True,
    ):
        """
        åˆå§‹åŒ–å„ªåŒ– AI æœå‹™

        Args:
            max_concurrent_ai: AI è™•ç†æœ€å¤§ä¸¦ç™¼æ•¸
            max_concurrent_notion: Notion å¯«å…¥æœ€å¤§ä¸¦ç™¼æ•¸
            max_global_concurrent: å…¨å±€æœ€å¤§ä¸¦ç™¼æ•¸
            enable_cache: æ˜¯å¦å•Ÿç”¨å¿«å–
            auto_notion_save: æ˜¯å¦è‡ªå‹•ä¿å­˜åˆ° Notion
        """
        # åˆå§‹åŒ–æ ¸å¿ƒçµ„ä»¶
        self.card_processor = AsyncCardProcessor(
            max_concurrent=max_concurrent_ai, enable_cache=enable_cache
        )

        self.batch_service = AsyncBatchService(
            card_processor=self.card_processor,
            max_global_concurrent=max_global_concurrent,
        )

        self.notion_manager = AsyncNotionManager(max_concurrent=max_concurrent_notion)

        self.auto_notion_save = auto_notion_save

        # æœå‹™ç‹€æ…‹
        self.is_running = False
        self.start_time = None

        # çµ±è¨ˆè³‡è¨Š
        self.service_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "avg_response_time": 0.0,
            "cache_hit_rate": 0.0,
            "notion_save_rate": 0.0,
        }

    async def start(self):
        """å•Ÿå‹•æœå‹™"""
        self.is_running = True
        self.start_time = datetime.now()
        print("ğŸš€ å„ªåŒ– AI æœå‹™å·²å•Ÿå‹•")

    async def stop(self):
        """åœæ­¢æœå‹™"""
        self.is_running = False
        await self.batch_service.shutdown()
        print("â¹ï¸ å„ªåŒ– AI æœå‹™å·²åœæ­¢")

    async def process_image(
        self,
        image_bytes: bytes,
        user_id: str,
        priority: ProcessingPriority = ProcessingPriority.NORMAL,
        enable_cache: Optional[bool] = None,
        save_to_notion: Optional[bool] = None,
        timeout: float = 30.0,
    ) -> Tuple[Dict[str, Any], Dict[str, Any]]:
        """
        è™•ç†å–®å¼µåœ–ç‰‡

        Args:
            image_bytes: åœ–ç‰‡äºŒé€²åˆ¶æ•¸æ“š
            user_id: ç”¨æˆ¶ID
            priority: è™•ç†å„ªå…ˆç´š
            enable_cache: æ˜¯å¦å•Ÿç”¨å¿«å–
            save_to_notion: æ˜¯å¦ä¿å­˜åˆ° Notion
            timeout: è™•ç†è¶…æ™‚æ™‚é–“

        Returns:
            Tuple[è™•ç†çµæœ, å…ƒæ•¸æ“š]
        """
        start_time = time.time()
        self.service_stats["total_requests"] += 1

        try:
            # AI è™•ç†
            result, ai_metadata = await self.card_processor.process_image_async(
                image_bytes=image_bytes,
                priority=priority,
                user_id=user_id,
                enable_cache=enable_cache,
                timeout=timeout,
            )

            # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜åˆ° Notion
            should_save = (
                save_to_notion if save_to_notion is not None else self.auto_notion_save
            )
            notion_results = []

            if should_save and not result.get("error") and result.get("cards"):
                notion_results = await self._save_cards_to_notion(
                    result["cards"], image_bytes
                )

            # çµ„åˆæœ€çµ‚çµæœ
            final_result = {
                **result,
                "notion_results": notion_results if notion_results else None,
            }

            # å»ºæ§‹å…ƒæ•¸æ“š
            processing_time = time.time() - start_time
            metadata = {
                "processing_time": processing_time,
                "user_id": user_id,
                "cache_hit": ai_metadata.cache_hit,
                "api_key_used": ai_metadata.api_key_used,
                "confidence_score": ai_metadata.confidence_score,
                "notion_saved": len(notion_results) if notion_results else 0,
                "priority": priority.name,
                "timestamp": datetime.now().isoformat(),
            }

            # æ›´æ–°çµ±è¨ˆ
            self._update_service_stats(
                processing_time, True, ai_metadata.cache_hit, len(notion_results) > 0
            )

            return final_result, metadata

        except Exception as e:
            processing_time = time.time() - start_time
            self._update_service_stats(processing_time, False, False, False)

            error_result = {"error": f"è™•ç†å¤±æ•—: {str(e)}"}
            error_metadata = {
                "processing_time": processing_time,
                "user_id": user_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

            return error_result, error_metadata

    async def process_batch(
        self,
        image_batch: List[bytes],
        user_id: str,
        priority: ProcessingPriority = ProcessingPriority.NORMAL,
        max_concurrent: Optional[int] = None,
        save_to_notion: Optional[bool] = None,
    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
        """
        æ‰¹æ¬¡è™•ç†å¤šå¼µåœ–ç‰‡

        Args:
            image_batch: åœ–ç‰‡æ•¸æ“šåˆ—è¡¨
            user_id: ç”¨æˆ¶ID
            priority: è™•ç†å„ªå…ˆç´š
            max_concurrent: æœ€å¤§ä¸¦ç™¼æ•¸
            save_to_notion: æ˜¯å¦ä¿å­˜åˆ° Notion

        Returns:
            Tuple[è™•ç†çµæœåˆ—è¡¨, æ‰¹æ¬¡å…ƒæ•¸æ“š]
        """
        start_time = time.time()
        batch_size = len(image_batch)

        # å‰µå»ºæ‰¹æ¬¡æœƒè©±
        session_id = await self.batch_service.create_batch_session(
            user_id=user_id, auto_process=True, max_concurrent=max_concurrent or 5
        )

        try:
            # æ·»åŠ æ‰€æœ‰é …ç›®åˆ°æ‰¹æ¬¡
            for i, image_bytes in enumerate(image_batch):
                item_id = f"{user_id}_batch_{int(time.time() * 1000)}_{i}"
                await self.batch_service.add_item_to_batch(
                    session_id=session_id,
                    item_id=item_id,
                    image_bytes=image_bytes,
                    priority=priority,
                )

            # è™•ç†æ‰¹æ¬¡
            batch_summary = await self.batch_service.process_batch(
                session_id=session_id, max_concurrent=max_concurrent
            )

            # ç²å–è™•ç†çµæœ
            results = await self.batch_service.get_batch_results(session_id)

            # è™•ç† Notion ä¿å­˜
            should_save = (
                save_to_notion if save_to_notion is not None else self.auto_notion_save
            )
            if should_save:
                await self._save_batch_results_to_notion(results, image_batch)

            # å»ºæ§‹æ‰¹æ¬¡å…ƒæ•¸æ“š
            processing_time = time.time() - start_time
            metadata = {
                "batch_size": batch_size,
                "processing_time": processing_time,
                "session_id": session_id,
                "user_id": user_id,
                "successful": batch_summary.get("successful", 0),
                "failed": batch_summary.get("failed", 0),
                "items_per_second": batch_summary.get("items_per_second", 0),
                "timestamp": datetime.now().isoformat(),
            }

            return results or [], metadata

        except Exception as e:
            return [], {
                "error": f"æ‰¹æ¬¡è™•ç†å¤±æ•—: {str(e)}",
                "batch_size": batch_size,
                "session_id": session_id,
            }
        finally:
            # æ¸…ç†æœƒè©±
            await self.batch_service.remove_batch_session(session_id)

    async def _save_cards_to_notion(
        self, cards: List[Dict[str, Any]], image_bytes: bytes
    ) -> List[Dict[str, Any]]:
        """ä¿å­˜åç‰‡åˆ° Notion"""
        try:
            return await self.notion_manager.create_batch_records(
                cards_data=cards, image_bytes_list=[image_bytes] * len(cards)
            )
        except Exception as e:
            print(f"ä¿å­˜åˆ° Notion å¤±æ•—: {e}")
            return [{"success": False, "error": str(e)} for _ in cards]

    async def _save_batch_results_to_notion(
        self, results: List[Dict[str, Any]], image_batch: List[bytes]
    ):
        """æ‰¹æ¬¡ä¿å­˜çµæœåˆ° Notion"""
        try:
            cards_to_save = []
            image_bytes_to_save = []

            for i, result in enumerate(results):
                if result.get("result") and result["result"].get("cards"):
                    for card in result["result"]["cards"]:
                        cards_to_save.append(card)
                        image_bytes_to_save.append(
                            image_batch[i] if i < len(image_batch) else None
                        )

            if cards_to_save:
                await self.notion_manager.create_batch_records(
                    cards_data=cards_to_save, image_bytes_list=image_bytes_to_save
                )

        except Exception as e:
            print(f"æ‰¹æ¬¡ä¿å­˜åˆ° Notion å¤±æ•—: {e}")

    def _update_service_stats(
        self, processing_time: float, success: bool, cache_hit: bool, notion_saved: bool
    ):
        """æ›´æ–°æœå‹™çµ±è¨ˆ"""
        if success:
            self.service_stats["successful_requests"] += 1
        else:
            self.service_stats["failed_requests"] += 1

        # æ›´æ–°å¹³å‡éŸ¿æ‡‰æ™‚é–“
        total_requests = self.service_stats["total_requests"]
        current_avg = self.service_stats["avg_response_time"]
        new_avg = (
            current_avg * (total_requests - 1) + processing_time
        ) / total_requests
        self.service_stats["avg_response_time"] = new_avg

        # æ›´æ–°å¿«å–å‘½ä¸­ç‡
        if cache_hit:
            # ç°¡åŒ–çš„å¿«å–å‘½ä¸­ç‡è¨ˆç®—
            self.service_stats["cache_hit_rate"] = (
                self.service_stats["cache_hit_rate"] * 0.9 + 0.1
            )

        # æ›´æ–° Notion ä¿å­˜ç‡
        if notion_saved:
            self.service_stats["notion_save_rate"] = (
                self.service_stats["notion_save_rate"] * 0.9 + 0.1
            )

    async def get_service_status(self) -> Dict[str, Any]:
        """ç²å–æœå‹™ç‹€æ…‹"""
        uptime = (
            (datetime.now() - self.start_time).total_seconds() if self.start_time else 0
        )

        # ç²å–å„çµ„ä»¶çµ±è¨ˆ
        ai_stats = await self.card_processor.get_performance_stats()
        batch_stats = await self.batch_service.get_service_stats()
        notion_stats = await self.notion_manager.get_performance_stats()

        return {
            "service_running": self.is_running,
            "uptime_seconds": uptime,
            "service_stats": self.service_stats,
            "ai_processor_stats": ai_stats,
            "batch_service_stats": batch_stats,
            "notion_manager_stats": notion_stats,
        }

    async def get_performance_report(self, hours: int = 24) -> Dict[str, Any]:
        """ç”Ÿæˆæ•ˆèƒ½å ±å‘Š"""
        service_status = await self.get_service_status()

        # è¨ˆç®—æ•ˆèƒ½æŒ‡æ¨™
        total_requests = self.service_stats["total_requests"]
        success_rate = (
            self.service_stats["successful_requests"] / total_requests
            if total_requests > 0
            else 0.0
        )

        # è¨ˆç®—ååé‡
        uptime_hours = service_status["uptime_seconds"] / 3600
        throughput = total_requests / uptime_hours if uptime_hours > 0 else 0.0

        return {
            "report_period_hours": hours,
            "total_requests": total_requests,
            "success_rate": success_rate,
            "avg_response_time": self.service_stats["avg_response_time"],
            "cache_hit_rate": self.service_stats["cache_hit_rate"],
            "notion_save_rate": self.service_stats["notion_save_rate"],
            "throughput_per_hour": throughput,
            "component_health": await self._get_component_health(),
            "recommendations": await self._generate_performance_recommendations(),
        }

    async def _get_component_health(self) -> Dict[str, Any]:
        """ç²å–çµ„ä»¶å¥åº·ç‹€æ…‹"""
        return {
            "ai_processor": await self.card_processor.health_check(),
            "batch_service": await self.batch_service.health_check(),
            "notion_manager": await self.notion_manager.health_check(),
        }

    async def _generate_performance_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ•ˆèƒ½å„ªåŒ–å»ºè­°"""
        recommendations = []

        # æª¢æŸ¥å¿«å–å‘½ä¸­ç‡
        if self.service_stats["cache_hit_rate"] < 0.3:
            recommendations.append("è€ƒæ…®èª¿æ•´å¿«å–ç­–ç•¥æˆ–å¢åŠ å¿«å–å¤§å°")

        # æª¢æŸ¥éŸ¿æ‡‰æ™‚é–“
        if self.service_stats["avg_response_time"] > 10.0:
            recommendations.append("å¹³å‡éŸ¿æ‡‰æ™‚é–“è¼ƒé«˜ï¼Œè€ƒæ…®å¢åŠ ä¸¦ç™¼æ•¸æˆ–å„ªåŒ– AI æ¨¡å‹")

        # æª¢æŸ¥æˆåŠŸç‡
        total_requests = self.service_stats["total_requests"]
        success_rate = (
            self.service_stats["successful_requests"] / total_requests
            if total_requests > 0
            else 1.0
        )
        if success_rate < 0.95:
            recommendations.append("æˆåŠŸç‡åä½ï¼Œæª¢æŸ¥ API é‡‘é‘°é…é¡å’Œç¶²è·¯é€£æ¥")

        return recommendations

    async def health_check(self) -> Dict[str, Any]:
        """ç¶œåˆå¥åº·æª¢æŸ¥"""
        try:
            component_health = await self._get_component_health()

            # åˆ¤æ–·æ•´é«”å¥åº·ç‹€æ…‹
            all_healthy = all(
                health.get("status") == "healthy"
                for health in component_health.values()
            )

            overall_status = "healthy" if all_healthy else "degraded"

            # æª¢æŸ¥æœå‹™è² è¼‰
            if self.service_stats["total_requests"] > 0:
                success_rate = (
                    self.service_stats["successful_requests"]
                    / self.service_stats["total_requests"]
                )
                if success_rate < 0.8:
                    overall_status = "unhealthy"

            return {
                "status": overall_status,
                "service_running": self.is_running,
                "components": component_health,
                "last_check": datetime.now().isoformat(),
            }

        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "last_check": datetime.now().isoformat(),
            }


# ä¾¿åˆ©å‡½æ•¸
async def create_optimized_ai_service(
    max_concurrent: int = 15,
    cache_memory_mb: int = 100,
    cache_disk_mb: int = 500,
    auto_start: bool = True,
) -> OptimizedAIService:
    """
    å‰µå»ºä¸¦é…ç½®å„ªåŒ– AI æœå‹™

    Args:
        max_concurrent: æœ€å¤§ä¸¦ç™¼æ•¸
        cache_memory_mb: è¨˜æ†¶é«”å¿«å–å¤§å°ï¼ˆMBï¼‰
        cache_disk_mb: ç£ç¢Ÿå¿«å–å¤§å°ï¼ˆMBï¼‰
        auto_start: æ˜¯å¦è‡ªå‹•å•Ÿå‹•

    Returns:
        é…ç½®å¥½çš„ OptimizedAIService å¯¦ä¾‹
    """
    service = OptimizedAIService(
        max_concurrent_ai=max_concurrent,
        max_concurrent_notion=max_concurrent // 2,
        max_global_concurrent=max_concurrent * 3,
        enable_cache=True,
        auto_notion_save=True,
    )

    if auto_start:
        await service.start()

    return service
