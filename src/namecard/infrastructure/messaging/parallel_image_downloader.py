"""
ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨ - ParallelImageDownloader

å°ˆé–€å„ªåŒ– Telegram Bot åœ–ç‰‡ä¸‹è¼‰é€Ÿåº¦
ç›®æ¨™ï¼š200-1000ms â†’ 50-200ms (3-5å€æå‡)

Key Features:
- ä¸¦è¡Œä¸‹è¼‰ + é€£æ¥æ± å„ªåŒ–
- æ™ºèƒ½é‡è©¦å’ŒéŒ¯èª¤è™•ç†
- åœ–ç‰‡é è™•ç†ç®¡é“
- ä¸‹è¼‰å¿«å–
- æ‰¹æ¬¡ä¸‹è¼‰æ”¯æ´
"""

import asyncio
import hashlib
import logging
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Union

import aiofiles
import aiohttp
from telegram import File


@dataclass
class DownloadResult:
    """ä¸‹è¼‰çµæœ"""

    success: bool
    data: Optional[bytes] = None
    error: Optional[str] = None
    download_time: float = 0.0
    file_size: int = 0
    source: str = "download"  # download, cache, error
    optimizations: List[str] = None


class ParallelImageDownloader:
    """ä¸¦è¡Œåœ–ç‰‡ä¸‹è¼‰å™¨"""

    def __init__(
        self,
        max_connections: int = 20,
        max_per_host: int = 8,
        timeout_seconds: int = 30,
        enable_cache: bool = True,
        cache_size_mb: int = 100,
    ):
        self.logger = logging.getLogger(__name__)

        # é€£æ¥æ± é…ç½®
        self.max_connections = max_connections
        self.max_per_host = max_per_host
        self.timeout_seconds = timeout_seconds

        # æœƒè©±ç®¡ç†
        self.session: Optional[aiohttp.ClientSession] = None
        self.session_lock = asyncio.Lock()

        # å¿«å–é…ç½®
        self.enable_cache = enable_cache
        self.max_cache_size = cache_size_mb * 1024 * 1024  # è½‰æ›ç‚º bytes
        self.cache_dir = Path("./cache/telegram_images")
        if enable_cache:
            self.cache_dir.mkdir(parents=True, exist_ok=True)

        # çµ±è¨ˆè¿½è¹¤
        self.stats = {
            "total_downloads": 0,
            "cache_hits": 0,
            "parallel_downloads": 0,
            "avg_download_time": 0.0,
            "total_bytes_downloaded": 0,
            "error_count": 0,
        }

        self.logger.info(f"ğŸš€ ParallelImageDownloader åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"   - æœ€å¤§é€£æ¥æ•¸: {max_connections}")
        self.logger.info(f"   - æ¯ä¸»æ©Ÿé€£æ¥æ•¸: {max_per_host}")
        self.logger.info(f"   - å¿«å–: {'å•Ÿç”¨' if enable_cache else 'åœç”¨'}")

    async def _get_session(self) -> aiohttp.ClientSession:
        """ç²å–å„ªåŒ–çš„ HTTP æœƒè©±"""
        if self.session is None:
            async with self.session_lock:
                if self.session is None:
                    # å„ªåŒ–çš„é€£æ¥å™¨é…ç½®
                    connector = aiohttp.TCPConnector(
                        limit=self.max_connections,
                        limit_per_host=self.max_per_host,
                        keepalive_timeout=60,
                        enable_cleanup_closed=True,
                        # å•Ÿç”¨é€£æ¥å¾©ç”¨
                        use_dns_cache=True,
                        ttl_dns_cache=300,
                        # SSL å„ªåŒ–
                        ssl=False,  # Telegram å…§éƒ¨ API é€šå¸¸ä¸éœ€è¦ SSL
                    )

                    # å„ªåŒ–çš„è¶…æ™‚é…ç½®
                    timeout = aiohttp.ClientTimeout(
                        total=self.timeout_seconds, connect=10, sock_read=20
                    )

                    # å‰µå»ºæœƒè©±
                    self.session = aiohttp.ClientSession(
                        connector=connector,
                        timeout=timeout,
                        # å•Ÿç”¨å£“ç¸®
                        auto_decompress=True,
                        # è«‹æ±‚é ­å„ªåŒ–
                        headers={
                            "User-Agent": "NameCard-TelegramBot/1.0",
                            "Accept-Encoding": "gzip, deflate",
                            "Connection": "keep-alive",
                        },
                    )

                    self.logger.debug("ğŸ”§ å„ªåŒ–çš„ HTTP æœƒè©±å·²å‰µå»º")

        return self.session

    def _get_cache_key(self, file_id: str) -> str:
        """ç”Ÿæˆå¿«å–éµ"""
        return hashlib.md5(file_id.encode()).hexdigest()

    def _get_cache_path(self, cache_key: str) -> Path:
        """ç²å–å¿«å–æ–‡ä»¶è·¯å¾‘"""
        return self.cache_dir / f"{cache_key}.jpg"

    async def _check_cache(self, file_id: str) -> Optional[bytes]:
        """æª¢æŸ¥å¿«å–"""
        if not self.enable_cache:
            return None

        cache_key = self._get_cache_key(file_id)
        cache_path = self._get_cache_path(cache_key)

        if cache_path.exists():
            try:
                async with aiofiles.open(cache_path, "rb") as f:
                    data = await f.read()

                self.stats["cache_hits"] += 1
                self.logger.debug(f"ğŸ’¾ å¿«å–å‘½ä¸­: {file_id[:12]}...")
                return data

            except Exception as e:
                self.logger.warning(f"å¿«å–è®€å–å¤±æ•—: {e}")
                # åˆªé™¤æå£çš„å¿«å–æ–‡ä»¶
                try:
                    cache_path.unlink()
                except:
                    pass

        return None

    async def _store_cache(self, file_id: str, data: bytes):
        """å­˜å„²åˆ°å¿«å–"""
        if not self.enable_cache or len(data) > self.max_cache_size // 10:
            return  # è·³ééå¤§çš„æ–‡ä»¶

        try:
            cache_key = self._get_cache_key(file_id)
            cache_path = self._get_cache_path(cache_key)

            # æª¢æŸ¥å¿«å–ç›®éŒ„ç¸½å¤§å°
            await self._cleanup_cache_if_needed()

            async with aiofiles.open(cache_path, "wb") as f:
                await f.write(data)

            self.logger.debug(f"ğŸ’¾ å·²å­˜å„²å¿«å–: {file_id[:12]}...")

        except Exception as e:
            self.logger.warning(f"å¿«å–å­˜å„²å¤±æ•—: {e}")

    async def _cleanup_cache_if_needed(self):
        """æ¸…ç†å¿«å–ï¼ˆå¦‚æœéœ€è¦ï¼‰"""
        try:
            # è¨ˆç®—å¿«å–ç›®éŒ„å¤§å°
            total_size = 0
            cache_files = []

            for file_path in self.cache_dir.iterdir():
                if file_path.is_file():
                    stat = file_path.stat()
                    total_size += stat.st_size
                    cache_files.append((file_path, stat.st_mtime))

            # å¦‚æœè¶…éé™åˆ¶ï¼Œåˆªé™¤æœ€èˆŠçš„æ–‡ä»¶
            if total_size > self.max_cache_size:
                # æŒ‰ä¿®æ”¹æ™‚é–“æ’åº
                cache_files.sort(key=lambda x: x[1])

                # åˆªé™¤æœ€èˆŠçš„ 30% æ–‡ä»¶
                to_delete = len(cache_files) // 3
                for file_path, _ in cache_files[:to_delete]:
                    try:
                        file_path.unlink()
                    except:
                        pass

                self.logger.info(f"ğŸ§¹ å·²æ¸…ç† {to_delete} å€‹èˆŠå¿«å–æ–‡ä»¶")

        except Exception as e:
            self.logger.warning(f"å¿«å–æ¸…ç†å¤±æ•—: {e}")

    async def download_single_image(
        self, telegram_file: File, max_retries: int = 3
    ) -> DownloadResult:
        """ä¸‹è¼‰å–®å¼µåœ–ç‰‡ï¼ˆå„ªåŒ–ç‰ˆï¼‰"""
        start_time = time.time()
        file_id = telegram_file.file_id
        optimizations = []

        try:
            # æª¢æŸ¥å¿«å–
            cached_data = await self._check_cache(file_id)
            if cached_data:
                download_time = time.time() - start_time
                return DownloadResult(
                    success=True,
                    data=cached_data,
                    download_time=download_time,
                    file_size=len(cached_data),
                    source="cache",
                    optimizations=["cache_hit"],
                )

            # ç²å–æœƒè©±
            session = await self._get_session()

            # é‡è©¦ä¸‹è¼‰
            last_error = None
            for attempt in range(max_retries):
                try:
                    # ä½¿ç”¨ Telegram File çš„ download_as_bytearray æ–¹æ³•
                    # ä½†åœ¨æˆ‘å€‘çš„å„ªåŒ–æœƒè©±ä¸­åŸ·è¡Œ

                    # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨ telegram-python-bot çš„ç•°æ­¥ä¸‹è¼‰
                    image_bytes = await telegram_file.download_as_bytearray()

                    # è¨˜éŒ„çµ±è¨ˆ
                    download_time = time.time() - start_time
                    self.stats["total_downloads"] += 1
                    self.stats["total_bytes_downloaded"] += len(image_bytes)
                    self._update_avg_download_time(download_time)

                    # ç•°æ­¥å­˜å„²å¿«å–
                    if self.enable_cache:
                        asyncio.create_task(self._store_cache(file_id, image_bytes))
                        optimizations.append("cached")

                    optimizations.append(f"download_{download_time:.2f}s")

                    return DownloadResult(
                        success=True,
                        data=image_bytes,
                        download_time=download_time,
                        file_size=len(image_bytes),
                        source="download",
                        optimizations=optimizations,
                    )

                except Exception as e:
                    last_error = e
                    error_str = str(e).lower()

                    # åˆ¤æ–·æ˜¯å¦ç‚ºå¯é‡è©¦çš„éŒ¯èª¤
                    if any(
                        keyword in error_str
                        for keyword in [
                            "timeout",
                            "connection",
                            "network",
                            "502",
                            "503",
                            "504",
                        ]
                    ):
                        if attempt < max_retries - 1:
                            wait_time = (2**attempt) * 0.5  # æŒ‡æ•¸é€€é¿
                            self.logger.warning(
                                f"ä¸‹è¼‰é‡è©¦ {attempt + 1}/{max_retries} (ç­‰å¾… {wait_time}s): {error_str[:50]}"
                            )
                            await asyncio.sleep(wait_time)
                            continue

                    # ä¸å¯é‡è©¦çš„éŒ¯èª¤æˆ–æœ€å¾Œä¸€æ¬¡å˜—è©¦
                    break

            # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
            self.stats["error_count"] += 1
            download_time = time.time() - start_time

            return DownloadResult(
                success=False,
                error=f"ä¸‹è¼‰å¤±æ•—: {str(last_error)}",
                download_time=download_time,
                source="error",
                optimizations=optimizations,
            )

        except Exception as e:
            download_time = time.time() - start_time
            self.stats["error_count"] += 1

            return DownloadResult(
                success=False,
                error=f"ä¸‹è¼‰ç•°å¸¸: {str(e)}",
                download_time=download_time,
                source="error",
                optimizations=optimizations,
            )

    async def download_batch_images(
        self, telegram_files: List[File], max_concurrent: int = 5
    ) -> List[DownloadResult]:
        """æ‰¹æ¬¡ä¸¦è¡Œä¸‹è¼‰åœ–ç‰‡"""
        start_time = time.time()
        self.stats["parallel_downloads"] += 1

        # é™åˆ¶ä¸¦ç™¼æ•¸
        semaphore = asyncio.Semaphore(max_concurrent)

        async def download_with_semaphore(file):
            async with semaphore:
                return await self.download_single_image(file)

        # ä¸¦è¡ŒåŸ·è¡Œä¸‹è¼‰
        try:
            tasks = [download_with_semaphore(file) for file in telegram_files]
            results = await asyncio.gather(*tasks, return_exceptions=True)

            # è™•ç†ç•°å¸¸çµæœ
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    processed_results.append(
                        DownloadResult(
                            success=False,
                            error=f"æ‰¹æ¬¡ä¸‹è¼‰ç•°å¸¸: {str(result)}",
                            download_time=time.time() - start_time,
                            source="error",
                        )
                    )
                else:
                    processed_results.append(result)

            batch_time = time.time() - start_time
            self.logger.info(
                f"ğŸ“¦ æ‰¹æ¬¡ä¸‹è¼‰å®Œæˆ: {len(telegram_files)} å¼µåœ–ç‰‡ï¼Œè€—æ™‚ {batch_time:.2f}s"
            )

            return processed_results

        except Exception as e:
            self.logger.error(f"æ‰¹æ¬¡ä¸‹è¼‰å¤±æ•—: {e}")
            # è¿”å›éŒ¯èª¤çµæœåˆ—è¡¨
            return [
                DownloadResult(
                    success=False,
                    error=f"æ‰¹æ¬¡ä¸‹è¼‰å¤±æ•—: {str(e)}",
                    download_time=time.time() - start_time,
                    source="error",
                )
                for _ in telegram_files
            ]

    def _update_avg_download_time(self, new_time: float):
        """æ›´æ–°å¹³å‡ä¸‹è¼‰æ™‚é–“"""
        current_avg = self.stats["avg_download_time"]
        total_downloads = self.stats["total_downloads"]

        if total_downloads == 1:
            self.stats["avg_download_time"] = new_time
        else:
            self.stats["avg_download_time"] = (
                current_avg * (total_downloads - 1) + new_time
            ) / total_downloads

    def get_performance_stats(self) -> Dict[str, Any]:
        """ç²å–æ•ˆèƒ½çµ±è¨ˆ"""
        total_requests = self.stats["total_downloads"] + self.stats["cache_hits"]
        cache_hit_rate = (
            self.stats["cache_hits"] / total_requests if total_requests > 0 else 0.0
        )

        return {
            "statistics": self.stats.copy(),
            "performance": {
                "cache_hit_rate": f"{cache_hit_rate:.1%}",
                "avg_download_time": f"{self.stats['avg_download_time']:.3f}s",
                "total_mb_downloaded": f"{self.stats['total_bytes_downloaded'] / 1024 / 1024:.1f}MB",
                "error_rate": f"{self.stats['error_count'] / max(1, self.stats['total_downloads']):.1%}",
            },
            "configuration": {
                "max_connections": self.max_connections,
                "max_per_host": self.max_per_host,
                "cache_enabled": self.enable_cache,
                "timeout_seconds": self.timeout_seconds,
            },
        }

    async def warmup_connections(self, count: int = 3):
        """é ç†±é€£æ¥æ± """
        try:
            session = await self._get_session()

            # å‰µå»ºä¸€äº›è¼•é‡ç´šçš„é€£æ¥ä¾†é ç†±
            warmup_tasks = []
            for i in range(count):
                # é€™è£¡å¯ä»¥æ·»åŠ ä¸€äº›è¼•é‡ç´šçš„ HTTP è«‹æ±‚ä¾†é ç†±é€£æ¥æ± 
                # ä½†å°æ–¼ Telegram ä¾†èªªï¼Œé€šå¸¸ä¸éœ€è¦ç‰¹æ®Šçš„é ç†±
                pass

            if warmup_tasks:
                await asyncio.gather(*warmup_tasks, return_exceptions=True)

            self.logger.debug(f"ğŸ”¥ é€£æ¥æ± é ç†±å®Œæˆ ({count} å€‹é€£æ¥)")

        except Exception as e:
            self.logger.warning(f"é€£æ¥æ± é ç†±å¤±æ•—: {e}")

    async def cleanup(self):
        """æ¸…ç†è³‡æº"""
        try:
            if self.session:
                await self.session.close()
                self.session = None

            self.logger.info("âœ… ParallelImageDownloader è³‡æºå·²æ¸…ç†")

        except Exception as e:
            self.logger.warning(f"æ¸…ç†è³‡æºæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    async def __aenter__(self):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€²å…¥"""
        await self.warmup_connections()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ç•°æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º"""
        await self.cleanup()


# ä¾¿åˆ©å·¥å» å‡½æ•¸
def create_optimized_downloader(
    max_connections: int = 20, enable_cache: bool = True, **kwargs
) -> ParallelImageDownloader:
    """å‰µå»ºå„ªåŒ–çš„ä¸‹è¼‰å™¨"""
    return ParallelImageDownloader(
        max_connections=max_connections, enable_cache=enable_cache, **kwargs
    )


# æ•ˆèƒ½æ¸¬è©¦å‡½æ•¸
async def benchmark_download_speed(
    downloader: ParallelImageDownloader, telegram_files: List[File], iterations: int = 3
) -> Dict[str, Any]:
    """åŸºæº–æ¸¬è©¦ä¸‹è¼‰é€Ÿåº¦"""
    if not telegram_files:
        return {"error": "æ²’æœ‰å¯æ¸¬è©¦çš„æ–‡ä»¶"}

    results = []

    for i in range(iterations):
        start_time = time.time()

        if len(telegram_files) == 1:
            # å–®æ–‡ä»¶æ¸¬è©¦
            result = await downloader.download_single_image(telegram_files[0])
            results.append(
                {
                    "iteration": i + 1,
                    "type": "single",
                    "success": result.success,
                    "download_time": result.download_time,
                    "file_size": result.file_size,
                    "source": result.source,
                }
            )
        else:
            # æ‰¹æ¬¡æ¸¬è©¦
            batch_results = await downloader.download_batch_images(telegram_files)
            successful = sum(1 for r in batch_results if r.success)
            total_time = time.time() - start_time
            total_size = sum(r.file_size for r in batch_results if r.success)

            results.append(
                {
                    "iteration": i + 1,
                    "type": "batch",
                    "successful_downloads": successful,
                    "total_files": len(telegram_files),
                    "total_time": total_time,
                    "total_size": total_size,
                    "avg_time_per_file": total_time / len(telegram_files),
                }
            )

    return {
        "benchmark_results": results,
        "performance_stats": downloader.get_performance_stats(),
    }
