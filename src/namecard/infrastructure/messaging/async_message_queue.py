"""
ç•°æ­¥è¨Šæ¯ä½‡åˆ—ç³»çµ± - AsyncMessageQueue

æä¾›æ™ºèƒ½è¨Šæ¯æ’ç¨‹ã€æ‰¹æ¬¡åˆä½µã€å‹•æ…‹ä½µç™¼æ§åˆ¶å’Œé€£æ¥æ± å„ªåŒ–
åŸºæ–¼ ChatGPT å»ºè­°å’Œ Backend Architect è¨­è¨ˆå¯¦ä½œ

Features:
- 5ç´šå„ªå…ˆç´šæ’ç¨‹ (ç·Šæ€¥â†’é«˜â†’æ™®é€šâ†’ä½â†’æ‰¹æ¬¡)
- æ™ºèƒ½æ‰¹æ¬¡åˆä½µå’Œå»é‡
- å‹•æ…‹ä½µç™¼æ§åˆ¶ (3-20 adaptive)
- é€£æ¥æ± æ„ŸçŸ¥å’Œè‡ªå‹•å„ªåŒ–
- æŒ‡æ•¸é€€é¿é‡è©¦æ©Ÿåˆ¶
"""

import asyncio
import hashlib
import json
import logging
import time
from collections import defaultdict
from dataclasses import dataclass, field
from enum import IntEnum
from typing import Any, Callable, Dict, List, Optional, Union


class MessagePriority(IntEnum):
    """è¨Šæ¯å„ªå…ˆç´šæšèˆ‰"""

    EMERGENCY = 1  # ç·Šæ€¥ - ç«‹å³ç™¼é€ï¼Œç¹éæ’ç¨‹
    HIGH = 2  # é«˜ - å„ªå…ˆè™•ç†
    NORMAL = 3  # æ™®é€š - æ¨™æº–è™•ç†
    LOW = 4  # ä½ - å»¶å¾Œè™•ç†
    BATCH = 5  # æ‰¹æ¬¡ - åˆä½µè™•ç†


@dataclass
class QueuedMessage:
    """ä½‡åˆ—ä¸­çš„è¨Šæ¯ç‰©ä»¶"""

    chat_id: Union[int, str]
    text: str
    priority: MessagePriority
    created_at: float = field(default_factory=time.time)
    retry_count: int = 0
    max_retries: int = 3

    # å¯é¸åƒæ•¸
    parse_mode: Optional[str] = None
    context: Optional[str] = None  # æ‰¹æ¬¡ä¸Šä¸‹æ–‡
    message_type: Optional[str] = None  # è¨Šæ¯é¡å‹

    # å…§éƒ¨å±¬æ€§
    message_id: str = field(default="")
    batch_key: Optional[str] = None  # æ‰¹æ¬¡åˆä½µéµ

    def __post_init__(self):
        """åˆå§‹åŒ–å¾Œè™•ç†"""
        if not self.message_id:
            # ç”Ÿæˆå”¯ä¸€è¨Šæ¯ID
            content = f"{self.chat_id}:{self.text}:{self.created_at}"
            self.message_id = hashlib.md5(content.encode()).hexdigest()[:12]

        # ç”Ÿæˆæ‰¹æ¬¡åˆä½µéµ
        if self.priority == MessagePriority.BATCH:
            self.batch_key = self._generate_batch_key()

    def _generate_batch_key(self) -> str:
        """ç”Ÿæˆæ‰¹æ¬¡åˆä½µéµ"""
        # åŸºæ–¼ç”¨æˆ¶IDã€è¨Šæ¯é¡å‹å’Œä¸Šä¸‹æ–‡ç”Ÿæˆ
        key_parts = [str(self.chat_id)]

        if self.message_type:
            key_parts.append(self.message_type)
        if self.context:
            key_parts.append(self.context)

        return ":".join(key_parts)


class AsyncMessageQueue:
    """ç•°æ­¥è¨Šæ¯ä½‡åˆ—ç³»çµ±"""

    def __init__(
        self,
        max_queue_size: int = 10000,
        initial_concurrent_workers: int = 8,
        batch_size: int = 5,
        batch_timeout: float = 2.0,
        enable_smart_merging: bool = True,
    ):
        """
        åˆå§‹åŒ–ç•°æ­¥è¨Šæ¯ä½‡åˆ—

        Args:
            max_queue_size: ä½‡åˆ—æœ€å¤§å®¹é‡
            initial_concurrent_workers: åˆå§‹ä½µç™¼å·¥ä½œè€…æ•¸é‡
            batch_size: æ‰¹æ¬¡è™•ç†å¤§å°
            batch_timeout: æ‰¹æ¬¡è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
            enable_smart_merging: å•Ÿç”¨æ™ºèƒ½åˆä½µ
        """
        self.logger = logging.getLogger(__name__)

        # ä½‡åˆ—é…ç½®
        self.max_queue_size = max_queue_size
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.enable_smart_merging = enable_smart_merging

        # å¤šå„ªå…ˆç´šä½‡åˆ—
        self.queues = {
            priority: asyncio.Queue(maxsize=max_queue_size)
            for priority in MessagePriority
        }

        # å‹•æ…‹ä½µç™¼æ§åˆ¶
        self.min_workers = 3
        self.max_workers = 20
        self.current_workers = initial_concurrent_workers
        self.worker_semaphore = None  # å»¶é²å‰µå»ºï¼Œé¿å…äº‹ä»¶å¾ªç’°ç¶å®šå•é¡Œ

        # çµ±è¨ˆå’Œç›£æ§
        self.stats = {
            "total_enqueued": 0,
            "total_processed": 0,
            "total_failed": 0,
            "total_merged": 0,
            "current_queue_size": 0,
            "worker_adjustments": 0,
            "connection_pool_cleanups": 0,
        }

        # æ•ˆèƒ½ç›£æ§
        self.performance_window = []
        self.error_rate_window = []
        self.last_adjustment_time = time.time()
        self.adjustment_cooldown = 30  # 30ç§’èª¿æ•´å†·å»æœŸ

        # æ‰¹æ¬¡åˆä½µæš«å­˜
        self.pending_batches = defaultdict(list)
        self.batch_timers = {}

        # å·¥ä½œè€…æ§åˆ¶
        self.workers = []
        self.is_running = False
        self.shutdown_event = None  # å»¶é²å‰µå»ºï¼Œé¿å…äº‹ä»¶å¾ªç’°ç¶å®šå•é¡Œ

        # è¨Šæ¯ç™¼é€å™¨ï¼ˆç”±å¤–éƒ¨è¨­ç½®ï¼‰
        self.message_sender: Optional[Callable] = None

        self.logger.info(f"âœ… AsyncMessageQueue åˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"   - åˆå§‹ä½µç™¼å·¥ä½œè€…: {self.current_workers}")
        self.logger.info(f"   - æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        self.logger.info(
            f"   - æ™ºèƒ½åˆä½µ: {'å•Ÿç”¨' if self.enable_smart_merging else 'åœç”¨'}"
        )

    def _get_shutdown_event(self):
        """å®‰å…¨ç²å– shutdown_eventï¼Œç¢ºä¿åœ¨æ­£ç¢ºçš„äº‹ä»¶å¾ªç’°ä¸­å‰µå»º"""
        if self.shutdown_event is None:
            try:
                # ç²å–ç•¶å‰äº‹ä»¶å¾ªç’°
                current_loop = asyncio.get_running_loop()
                self.shutdown_event = asyncio.Event()
                self.logger.debug("ğŸ”§ åœ¨ç•¶å‰äº‹ä»¶å¾ªç’°ä¸­å‰µå»º shutdown_event")
            except RuntimeError:
                # æ²’æœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„ Event
                self.shutdown_event = asyncio.Event()
                self.logger.debug("ğŸ”§ å‰µå»ºæ–°çš„ shutdown_event")
        return self.shutdown_event

    def _get_worker_semaphore(self):
        """å®‰å…¨ç²å– worker_semaphoreï¼Œç¢ºä¿åœ¨æ­£ç¢ºçš„äº‹ä»¶å¾ªç’°ä¸­å‰µå»º"""
        if self.worker_semaphore is None:
            try:
                # ç²å–ç•¶å‰äº‹ä»¶å¾ªç’°
                current_loop = asyncio.get_running_loop()
                self.worker_semaphore = asyncio.Semaphore(self.current_workers)
                self.logger.debug(
                    f"ğŸ”§ åœ¨ç•¶å‰äº‹ä»¶å¾ªç’°ä¸­å‰µå»º worker_semaphore ({self.current_workers})"
                )
            except RuntimeError:
                # æ²’æœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„ Semaphore
                self.worker_semaphore = asyncio.Semaphore(self.current_workers)
                self.logger.debug(
                    f"ğŸ”§ å‰µå»ºæ–°çš„ worker_semaphore ({self.current_workers})"
                )
        return self.worker_semaphore

    def set_message_sender(self, sender: Callable):
        """è¨­ç½®è¨Šæ¯ç™¼é€å™¨å‡½æ•¸"""
        self.message_sender = sender
        self.logger.debug("âœ… è¨Šæ¯ç™¼é€å™¨å·²è¨­ç½®")

    async def start(self):
        """å•Ÿå‹•ä½‡åˆ—è™•ç†ç³»çµ±"""
        if self.is_running:
            self.logger.warning("âš ï¸ ä½‡åˆ—ç³»çµ±å·²åœ¨é‹è¡Œä¸­")
            return

        self.is_running = True
        self._get_shutdown_event().clear()

        # å•Ÿå‹•å·¥ä½œè€…
        for i in range(self.current_workers):
            worker = asyncio.create_task(self._worker(f"worker-{i}"))
            self.workers.append(worker)

        # å•Ÿå‹•ç›£æ§ä»»å‹™
        monitor_task = asyncio.create_task(self._performance_monitor())
        self.workers.append(monitor_task)

        self.logger.info(f"ğŸš€ ç•°æ­¥è¨Šæ¯ä½‡åˆ—ç³»çµ±å·²å•Ÿå‹•")
        self.logger.info(f"   - å·¥ä½œè€…æ•¸é‡: {len(self.workers) - 1}")  # æ¸›å»ç›£æ§ä»»å‹™

    async def stop(self):
        """åœæ­¢ä½‡åˆ—è™•ç†ç³»çµ±"""
        self.logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢ç•°æ­¥è¨Šæ¯ä½‡åˆ—ç³»çµ±...")

        self.is_running = False
        self._get_shutdown_event().set()

        # ç­‰å¾…æ‰€æœ‰å·¥ä½œè€…å®Œæˆ
        if self.workers:
            await asyncio.gather(*self.workers, return_exceptions=True)
            self.workers.clear()

        # æ¸…ç†å¾…è™•ç†çš„æ‰¹æ¬¡
        await self._flush_pending_batches()

        self.logger.info("âœ… ç•°æ­¥è¨Šæ¯ä½‡åˆ—ç³»çµ±å·²åœæ­¢")

    async def enqueue_message(
        self,
        chat_id: Union[int, str],
        text: str,
        priority: MessagePriority = MessagePriority.NORMAL,
        parse_mode: Optional[str] = None,
        context: Optional[str] = None,
        message_type: Optional[str] = None,
        max_retries: int = 3,
    ) -> str:
        """
        å°‡è¨Šæ¯åŠ å…¥ä½‡åˆ—

        Returns:
            str: è¨Šæ¯ID
        """
        # å‰µå»ºè¨Šæ¯ç‰©ä»¶
        message = QueuedMessage(
            chat_id=chat_id,
            text=text,
            priority=priority,
            parse_mode=parse_mode,
            context=context,
            message_type=message_type,
            max_retries=max_retries,
        )

        # ç·Šæ€¥è¨Šæ¯ç›´æ¥ç™¼é€ï¼Œç¹éæ’ç¨‹
        if priority == MessagePriority.EMERGENCY:
            self.logger.debug(f"ğŸš¨ ç·Šæ€¥è¨Šæ¯ç›´æ¥ç™¼é€: {message.message_id}")
            if self.message_sender:
                try:
                    await self.message_sender(chat_id, text, parse_mode)
                    self.stats["total_processed"] += 1
                    return message.message_id
                except Exception as e:
                    self.logger.error(f"âŒ ç·Šæ€¥è¨Šæ¯ç™¼é€å¤±æ•—: {e}")
                    self.stats["total_failed"] += 1
                    # é™ç´šåˆ°é«˜å„ªå…ˆç´šä½‡åˆ—
                    message.priority = MessagePriority.HIGH

        # æª¢æŸ¥ä½‡åˆ—å®¹é‡
        queue = self.queues[message.priority]
        if queue.full():
            self.logger.warning(
                f"âš ï¸ ä½‡åˆ—å·²æ»¿ ({message.priority.name})ï¼Œä¸Ÿæ£„è¨Šæ¯: {message.message_id}"
            )
            return message.message_id

        # æ‰¹æ¬¡è¨Šæ¯è™•ç†
        if priority == MessagePriority.BATCH and self.enable_smart_merging:
            await self._handle_batch_message(message)
        else:
            # ç›´æ¥åŠ å…¥ä½‡åˆ—
            await queue.put(message)
            self.stats["total_enqueued"] += 1
            self.stats["current_queue_size"] += 1

        self.logger.debug(
            f"ğŸ“¥ è¨Šæ¯å·²åŠ å…¥ä½‡åˆ—: {message.message_id} (å„ªå…ˆç´š: {priority.name})"
        )
        return message.message_id

    async def _handle_batch_message(self, message: QueuedMessage):
        """è™•ç†æ‰¹æ¬¡è¨Šæ¯ï¼Œå¯¦ç¾æ™ºèƒ½åˆä½µ"""
        batch_key = message.batch_key

        # åŠ å…¥å¾…è™•ç†æ‰¹æ¬¡
        self.pending_batches[batch_key].append(message)

        # è¨­ç½®æ‰¹æ¬¡å®šæ™‚å™¨
        if batch_key not in self.batch_timers:
            timer = asyncio.create_task(self._batch_timer(batch_key))
            self.batch_timers[batch_key] = timer

        # æª¢æŸ¥æ˜¯å¦é”åˆ°æ‰¹æ¬¡å¤§å°
        if len(self.pending_batches[batch_key]) >= self.batch_size:
            await self._flush_batch(batch_key)

    async def _batch_timer(self, batch_key: str):
        """æ‰¹æ¬¡å®šæ™‚å™¨ï¼Œè¶…æ™‚å¾Œè‡ªå‹•ç™¼é€"""
        try:
            await asyncio.sleep(self.batch_timeout)
            if batch_key in self.pending_batches:
                await self._flush_batch(batch_key)
        except asyncio.CancelledError:
            pass  # å®šæ™‚å™¨è¢«å–æ¶ˆ

    async def _flush_batch(self, batch_key: str):
        """ç™¼é€æ‰¹æ¬¡è¨Šæ¯"""
        if batch_key not in self.pending_batches:
            return

        messages = self.pending_batches.pop(batch_key)
        if not messages:
            return

        # å–æ¶ˆå®šæ™‚å™¨
        if batch_key in self.batch_timers:
            self.batch_timers[batch_key].cancel()
            del self.batch_timers[batch_key]

        # æ™ºèƒ½åˆä½µ
        merged_message = self._merge_messages(messages)
        if merged_message:
            # åŠ å…¥é«˜å„ªå…ˆç´šä½‡åˆ—å¿«é€Ÿè™•ç†
            await self.queues[MessagePriority.HIGH].put(merged_message)
            self.stats["total_enqueued"] += 1
            self.stats["current_queue_size"] += 1
            self.stats["total_merged"] += len(messages) - 1  # åˆä½µæ•¸é‡

            self.logger.debug(f"ğŸ”„ å·²åˆä½µ {len(messages)} æ¢æ‰¹æ¬¡è¨Šæ¯: {batch_key}")

    def _merge_messages(self, messages: List[QueuedMessage]) -> Optional[QueuedMessage]:
        """æ™ºèƒ½åˆä½µå¤šæ¢è¨Šæ¯"""
        if not messages:
            return None

        if len(messages) == 1:
            return messages[0]

        # å–ç¬¬ä¸€æ¢è¨Šæ¯ä½œç‚ºåŸºç¤
        base_message = messages[0]

        # æ ¹æ“šè¨Šæ¯é¡å‹æ±ºå®šåˆä½µç­–ç•¥
        if base_message.message_type == "card_processing_complete":
            # åç‰‡è™•ç†å®Œæˆè¨Šæ¯ - åˆä½µç‚ºçµ±è¨ˆæ‘˜è¦
            return self._merge_card_processing_messages(messages)
        elif base_message.message_type == "batch_progress":
            # æ‰¹æ¬¡é€²åº¦è¨Šæ¯ - åªä¿ç•™æœ€æ–°çš„
            return max(messages, key=lambda m: m.created_at)
        else:
            # é»˜èªåˆä½µç­–ç•¥ - ç°¡å–®åˆ—è¡¨
            return self._merge_default_messages(messages)

    def _merge_card_processing_messages(
        self, messages: List[QueuedMessage]
    ) -> QueuedMessage:
        """åˆä½µåç‰‡è™•ç†å®Œæˆè¨Šæ¯"""
        base_message = messages[0]
        count = len(messages)

        # æå–åç‰‡è³‡è¨Š
        cards = []
        for msg in messages:
            # ç°¡å–®è§£æåç‰‡è³‡è¨Šï¼ˆå¯¦éš›å¯¦ä½œæœƒæ›´è¤‡é›œï¼‰
            if "ğŸ‘¤" in msg.text and "(" in msg.text:
                start = msg.text.find("ğŸ‘¤") + 2
                end = (
                    msg.text.find("\n", start)
                    if "\n" in msg.text[start:]
                    else len(msg.text)
                )
                card_info = msg.text[start : start + end].strip()
                cards.append(card_info)

        # ç”Ÿæˆåˆä½µè¨Šæ¯
        merged_text = f"ğŸ“Š **æ‰¹æ¬¡è™•ç†å®Œæˆ**\n\n"
        merged_text += f"âœ… å·²è™•ç† {count} å¼µåç‰‡ï¼š\n"
        for i, card in enumerate(cards[:5], 1):  # æœ€å¤šé¡¯ç¤º5å¼µ
            merged_text += f"{i}. {card}\n"

        if len(cards) > 5:
            merged_text += f"... ä»¥åŠå…¶ä»– {len(cards) - 5} å¼µåç‰‡\n"

        merged_text += f"\nâ±ï¸ è™•ç†æ™‚é–“: {time.time() - base_message.created_at:.1f}ç§’"

        return QueuedMessage(
            chat_id=base_message.chat_id,
            text=merged_text,
            priority=MessagePriority.HIGH,  # æå‡å„ªå…ˆç´š
            parse_mode=base_message.parse_mode,
            context=base_message.context,
            message_type="batch_summary",
        )

    def _merge_default_messages(self, messages: List[QueuedMessage]) -> QueuedMessage:
        """é»˜èªè¨Šæ¯åˆä½µç­–ç•¥"""
        base_message = messages[0]

        if len(messages) <= 3:
            # å°‘é‡è¨Šæ¯ç›´æ¥çµ„åˆ
            combined_text = "\n\n".join(msg.text for msg in messages)
        else:
            # å¤§é‡è¨Šæ¯æ‘˜è¦
            combined_text = f"ğŸ“ **æ‰¹æ¬¡è¨Šæ¯æ‘˜è¦** ({len(messages)} æ¢)\n\n"
            combined_text += "\n".join(f"â€¢ {msg.text[:50]}..." for msg in messages[:3])
            if len(messages) > 3:
                combined_text += f"\n... ä»¥åŠå…¶ä»– {len(messages) - 3} æ¢è¨Šæ¯"

        return QueuedMessage(
            chat_id=base_message.chat_id,
            text=combined_text,
            priority=base_message.priority,
            parse_mode=base_message.parse_mode,
            context=base_message.context,
            message_type="merged_batch",
        )

    async def _flush_pending_batches(self):
        """æ¸…ç©ºæ‰€æœ‰å¾…è™•ç†çš„æ‰¹æ¬¡"""
        for batch_key in list(self.pending_batches.keys()):
            await self._flush_batch(batch_key)

    async def _worker(self, worker_name: str):
        """å·¥ä½œè€…å”ç¨‹ï¼Œè™•ç†ä½‡åˆ—ä¸­çš„è¨Šæ¯"""
        self.logger.debug(f"ğŸ”§ å·¥ä½œè€…å·²å•Ÿå‹•: {worker_name}")

        while self.is_running:
            try:
                # æŒ‰å„ªå…ˆç´šè™•ç†è¨Šæ¯
                message = await self._get_next_message()

                if message is None:
                    # æ²’æœ‰è¨Šæ¯ï¼ŒçŸ­æš«ä¼‘æ¯
                    await asyncio.sleep(0.1)
                    continue

                # ä½µç™¼æ§åˆ¶
                async with self._get_worker_semaphore():
                    await self._process_message(message, worker_name)

            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"âŒ å·¥ä½œè€… {worker_name} ç™¼ç”ŸéŒ¯èª¤: {e}")
                await asyncio.sleep(1)  # éŒ¯èª¤å¾Œæš«åœ

        self.logger.debug(f"ğŸ›‘ å·¥ä½œè€…å·²åœæ­¢: {worker_name}")

    async def _get_next_message(self) -> Optional[QueuedMessage]:
        """æŒ‰å„ªå…ˆç´šç²å–ä¸‹ä¸€æ¢è¨Šæ¯"""
        # æŒ‰å„ªå…ˆç´šé †åºæª¢æŸ¥ä½‡åˆ—
        for priority in MessagePriority:
            queue = self.queues[priority]
            try:
                message = queue.get_nowait()
                self.stats["current_queue_size"] -= 1
                return message
            except asyncio.QueueEmpty:
                continue

        return None

    async def _process_message(self, message: QueuedMessage, worker_name: str):
        """è™•ç†å–®æ¢è¨Šæ¯"""
        start_time = time.time()

        try:
            if not self.message_sender:
                raise RuntimeError("è¨Šæ¯ç™¼é€å™¨æœªè¨­ç½®")

            # ç™¼é€è¨Šæ¯
            await self.message_sender(message.chat_id, message.text, message.parse_mode)

            # è¨˜éŒ„æˆåŠŸ
            processing_time = time.time() - start_time
            self.performance_window.append(processing_time)
            self.error_rate_window.append(0)  # æˆåŠŸ
            self.stats["total_processed"] += 1

            self.logger.debug(
                f"âœ… è¨Šæ¯è™•ç†æˆåŠŸ: {message.message_id} ({processing_time:.2f}s) - {worker_name}"
            )

        except Exception as e:
            # è¨˜éŒ„å¤±æ•—
            processing_time = time.time() - start_time
            self.performance_window.append(processing_time)
            self.error_rate_window.append(1)  # å¤±æ•—

            self.logger.error(f"âŒ è¨Šæ¯è™•ç†å¤±æ•—: {message.message_id} - {e}")

            # é‡è©¦é‚è¼¯
            if message.retry_count < message.max_retries:
                message.retry_count += 1
                # æŒ‡æ•¸é€€é¿é‡è©¦
                retry_delay = min(2**message.retry_count, 60)

                self.logger.info(
                    f"ğŸ”„ è¨Šæ¯é‡è©¦ {message.retry_count}/{message.max_retries} (å»¶é² {retry_delay}s): {message.message_id}"
                )

                # å»¶é²å¾Œé‡æ–°åŠ å…¥ä½‡åˆ—
                asyncio.create_task(self._retry_message(message, retry_delay))
            else:
                self.stats["total_failed"] += 1
                self.logger.error(f"ğŸ’€ è¨Šæ¯æœ€çµ‚å¤±æ•—: {message.message_id}")

        # é™åˆ¶æ•ˆèƒ½çª—å£å¤§å°
        if len(self.performance_window) > 100:
            self.performance_window = self.performance_window[-50:]
        if len(self.error_rate_window) > 100:
            self.error_rate_window = self.error_rate_window[-50:]

    async def _retry_message(self, message: QueuedMessage, delay: float):
        """å»¶é²é‡è©¦è¨Šæ¯"""
        await asyncio.sleep(delay)
        if self.is_running:
            # é™ä½å„ªå…ˆç´šé‡æ–°åŠ å…¥ä½‡åˆ—
            if message.priority.value < MessagePriority.LOW.value:
                message.priority = MessagePriority(message.priority.value + 1)

            queue = self.queues[message.priority]
            if not queue.full():
                await queue.put(message)
                self.stats["current_queue_size"] += 1

    async def _performance_monitor(self):
        """æ•ˆèƒ½ç›£æ§å’Œå‹•æ…‹èª¿æ•´"""
        self.logger.debug("ğŸ“Š æ•ˆèƒ½ç›£æ§å™¨å·²å•Ÿå‹•")

        while self.is_running:
            try:
                await asyncio.sleep(10)  # æ¯10ç§’æª¢æŸ¥ä¸€æ¬¡

                # è¨ˆç®—æ•ˆèƒ½æŒ‡æ¨™
                if len(self.error_rate_window) >= 10:
                    recent_errors = self.error_rate_window[-20:]
                    error_rate = sum(recent_errors) / len(recent_errors)

                    # å‹•æ…‹èª¿æ•´ä½µç™¼æ•¸
                    await self._adjust_concurrency(error_rate)

                # è¨˜éŒ„çµ±è¨ˆ
                self.logger.debug(f"ğŸ“ˆ ä½‡åˆ—çµ±è¨ˆ: {self._get_queue_stats()}")

            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"âŒ æ•ˆèƒ½ç›£æ§éŒ¯èª¤: {e}")

        self.logger.debug("ğŸ›‘ æ•ˆèƒ½ç›£æ§å™¨å·²åœæ­¢")

    async def _adjust_concurrency(self, error_rate: float):
        """æ ¹æ“šéŒ¯èª¤ç‡å‹•æ…‹èª¿æ•´ä½µç™¼æ•¸"""
        current_time = time.time()

        # æª¢æŸ¥èª¿æ•´å†·å»æœŸ
        if current_time - self.last_adjustment_time < self.adjustment_cooldown:
            return

        old_workers = self.current_workers

        if error_rate > 0.3:  # éŒ¯èª¤ç‡ > 30%
            # é™ä½ä½µç™¼æ•¸
            new_workers = max(self.min_workers, self.current_workers - 2)
        elif (
            error_rate < 0.1
            and self.stats["total_processed"] > self.current_workers * 20
        ):
            # éŒ¯èª¤ç‡ < 10% ä¸”è™•ç†é‡è¶³å¤ ï¼Œå¢åŠ ä½µç™¼æ•¸
            new_workers = min(self.max_workers, self.current_workers + 1)
        else:
            return  # ä¸éœ€è¦èª¿æ•´

        if new_workers != old_workers:
            self.current_workers = new_workers

            # æ›´æ–° Semaphoreï¼ˆå‰µå»ºæ–°çš„ï¼Œå› ç‚º asyncio.Semaphore ä¸æ”¯æ´å‹•æ…‹èª¿æ•´ï¼‰
            try:
                # ç²å–ç•¶å‰äº‹ä»¶å¾ªç’°
                current_loop = asyncio.get_running_loop()
                self.worker_semaphore = asyncio.Semaphore(new_workers)
                self.logger.debug(
                    f"ğŸ”§ åœ¨ç•¶å‰äº‹ä»¶å¾ªç’°ä¸­é‡å»º worker_semaphore ({new_workers})"
                )
            except RuntimeError:
                # æ²’æœ‰é‹è¡Œä¸­çš„äº‹ä»¶å¾ªç’°ï¼Œå‰µå»ºæ–°çš„ Semaphore
                self.worker_semaphore = asyncio.Semaphore(new_workers)
                self.logger.debug(f"ğŸ”§ é‡å»º worker_semaphore ({new_workers})")

            self.last_adjustment_time = current_time
            self.stats["worker_adjustments"] += 1

            self.logger.info(
                f"ğŸ”§ ä½µç™¼æ•¸èª¿æ•´: {old_workers} â†’ {new_workers} (éŒ¯èª¤ç‡: {error_rate:.1%})"
            )

    def _get_queue_stats(self) -> Dict[str, Any]:
        """ç²å–ä½‡åˆ—çµ±è¨ˆè³‡è¨Š"""
        queue_sizes = {
            priority.name: self.queues[priority].qsize() for priority in MessagePriority
        }

        return {
            "queue_sizes": queue_sizes,
            "current_workers": self.current_workers,
            "total_enqueued": self.stats["total_enqueued"],
            "total_processed": self.stats["total_processed"],
            "total_failed": self.stats["total_failed"],
            "total_merged": self.stats["total_merged"],
            "pending_batches": len(self.pending_batches),
            "error_rate": (
                sum(self.error_rate_window[-20:]) / len(self.error_rate_window[-20:])
                if len(self.error_rate_window) >= 20
                else 0
            ),
        }

    def get_health_status(self) -> Dict[str, Any]:
        """ç²å–å¥åº·ç‹€æ…‹"""
        stats = self._get_queue_stats()

        # å¥åº·æª¢æŸ¥
        is_healthy = (
            self.is_running
            and stats["error_rate"] < 0.5
            and sum(stats["queue_sizes"].values()) < self.max_queue_size * 0.8
        )

        return {
            "status": "healthy" if is_healthy else "degraded",
            "is_running": self.is_running,
            "uptime": time.time() - getattr(self, "_start_time", time.time()),
            "statistics": stats,
            "recommendations": self._get_health_recommendations(stats),
        }

    def _get_health_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """ç²å–å¥åº·å»ºè­°"""
        recommendations = []

        if stats["error_rate"] > 0.3:
            recommendations.append("éŒ¯èª¤ç‡åé«˜ï¼Œå»ºè­°æª¢æŸ¥é€£æ¥æ± é…ç½®")

        if sum(stats["queue_sizes"].values()) > self.max_queue_size * 0.7:
            recommendations.append("ä½‡åˆ—æ¥è¿‘æ»¿è¼‰ï¼Œå»ºè­°å¢åŠ å·¥ä½œè€…æ•¸é‡")

        if stats["total_merged"] > 0:
            merge_ratio = stats["total_merged"] / max(1, stats["total_processed"])
            if merge_ratio > 0.5:
                recommendations.append("æ‰¹æ¬¡åˆä½µæ•ˆæœè‰¯å¥½ï¼Œç³»çµ±é‹è¡Œæœ€ä½³åŒ–")

        if not recommendations:
            recommendations.append("ç³»çµ±é‹è¡Œæ­£å¸¸")

        return recommendations


# ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class BatchContext:
    """æ‰¹æ¬¡è™•ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self, queue: AsyncMessageQueue, context_name: str):
        self.queue = queue
        self.context_name = context_name
        self.message_count = 0

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        # å¼·åˆ¶ç™¼é€å¾…è™•ç†çš„æ‰¹æ¬¡
        await self.queue._flush_pending_batches()

    async def send_message(
        self,
        chat_id: Union[int, str],
        text: str,
        message_type: Optional[str] = None,
        **kwargs,
    ) -> str:
        """åœ¨æ‰¹æ¬¡ä¸Šä¸‹æ–‡ä¸­ç™¼é€è¨Šæ¯"""
        self.message_count += 1

        return await self.queue.enqueue_message(
            chat_id=chat_id,
            text=text,
            priority=MessagePriority.BATCH,
            context=self.context_name,
            message_type=message_type,
            **kwargs,
        )
